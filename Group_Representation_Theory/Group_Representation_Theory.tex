% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}\pagecolor[RGB]{28,30,38} \color[RGB]{213,216,218}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Group Representation Theory},
  pdfauthor={Kexing Ying},
  colorlinks=true,
  linkcolor=Maroon,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=red,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin = 1.5in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{tikz}
\usepackage{physics}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{esint}
\usepackage{pst-node}
\usepackage{auto-pst-pdf}
\usepackage{tikz-cd} 
\usepackage[ruled,vlined]{algorithm2e}
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{definition*}{Definition}
\newtheorem{prop}{Proposition}
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem*{remark}{Remark}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{example}{Example}[section]
\newcommand{\diag}{\mathop{\mathrm{diag}}}
\newcommand{\Arg}{\mathop{\mathrm{Arg}}}
\newcommand{\hess}{\mathop{\mathrm{Hess}}}
% the redefinition for the missing \setminus must be delayed
\AtBeginDocument{\renewcommand{\setminus}{\mathbin{\backslash}}}

\title{Group Representation Theory}
\author{Kexing Ying}
\date{July 24, 2021}

\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\newpage

\section{Introduction}

Group representation theory is a field of mathematics that applies linear algebra 
to study properties of groups. The field itself originated through a letter 
from Dedekind to Frobenius in which he noted that, given \(f = \det A\), where 
\(A\) is the Cayley table of a group of \(n\) elements, by factorising \(f\) 
into irreducible polynomials, \(f = \prod_i f_i^{d_i}\), we have \(d_i = \deg f_i\). 
And this led Frobenius to invent group representation theory.

Group representation theory is applicable in many different areas.
\begin{itemize}
  \item Group theory arises in Klein's "Erlangen program" as symmetries of 
    geometric spaces.
  \item Burnside in 1904 proves the following using representation theory 
    (and so shall we later on)
    \begin{proposition}
      Let \(G\) be a group such that \(|G| = p^r q^s\) where \(p, q\) are 
      prime and \(r + s \ge 2\), then \(G\) is not simple.
    \end{proposition}
  \item In number theory, representations of Galois groups arises in the 
    number field case 
    \[\overline{F} / F, \mathbb{Q} \subseteq F, [F : \mathbb{Q}] < \infty,\]
    which has implications in Wiles' proof of Fermat's last theorem.
  \item In chemistry the symmetry and rotation of molecules can be represented 
    by group actions.
  \item In quantum mechanics, spherical symmetry gives rise to discrete energy 
    levels, orbitals, etc.
  \item In differential geometry, the vector space of solutions is a representation 
    of the symmetry group of an equation.
\end{itemize}

Recalling the definition of a group, informally, the representation of a group \(G\) 
is a way if writing group elements as linear transformations of a vector space 
such that the natural group properties are satisfied. 

Some examples of group representations are the following:
\begin{itemize}
  \item For all group \(G\), the trivial representation of \(G\) is \(\rho\) such 
    that \(\rho(g) = \text{id}\) for all \(g \in G\).
  \item Let \(\zeta \in \mathbb{C}\) be a \(n\)-th root of \(1\) and let 
    \(G = C_n = \{1, g, \cdots, g^{n - 1}\}\). Then \(\rho : g^i \mapsto (\zeta^i)\)
    is a representation of \(G\).
  \item In the case \(G = S_n\), the mapping of \(\sigma \in S_n\) to its 
    corresponding permutation matrix \(P_\sigma\) is a representation of \(G\).
  \item Another representation of \(S_n\) is 
    \(\sigma \in S_n \mapsto (\text{sign}(\sigma))\)\footnote{\(\text{sign}(\sigma) = \det P_\sigma\)}.
  \item Let \(G = D_n\) the dihedral group of order \(2n\). Then, a representation 
    \(D_n\) maps elements of \(D_n\) to the corresponding \(2 \times 2\) matrices 
    which rotates/reflects \(\mathbb{R}^2\) by the appropriate amount.
\end{itemize}

We shall in this module study and construct representations, and furthermore, 
classify up to isomorphism finite-dimensional complex representations of 
every finite group \(G\). 

\section{Fundamentals of Group Representation}

\begin{definition}[Representation]
  Let \(G\) be a group, then a representation of \(G\) is the pair \((V, \rho)\) 
  where \(V\) is a (finite-dimensional) vector space and \(\rho : G \mapsto GL(V)\) 
  is a group homomorphism.
\end{definition}

Alternatively, we may consider a group representation of \(G\) is a group action 
\((\cdot) : G \times V \to V : (g, v) \mapsto v\) such that \((\cdot)\) is 
linear with respect to the second parameter. In particular, we recall a group 
action \((\cdot)\) satisfies \(e \cdot v = v\) and 
\(g \cdot (h \cdot v) = gh \cdot v\). 

\begin{definition}[Dimension of a Representation]
  If \((V, \rho)\) is a representation of \(G\), then the dimension of 
  \((V, \rho)\) is \(\dim(V, \rho) = \dim V\).
\end{definition}

Similar to other objects in mathematics, we introduce a notion of morphisms 
between representations.

\begin{definition}[Homomorphism of Representation]
  Let \(G\) be a group and \((V, \rho_V)\) and \((W, \rho_W)\) be two representations 
  of \(G\). Then a homomorphism of representations is a linear map 
  \(T : V \to W\) such that for all \(g \in G\),
  \[T \circ \rho_V(g) = \rho_W(g) \circ T.\]
  Furthermore, we say \(T\) is an isomorphism is bijective (or equivalently, 
  it has an inverse which is also a homomorphism).
\end{definition}

In particular, one might imagine the homomorphism as a linear map such that 
the following diagram commute.
\[\begin{tikzcd}
  V \arrow{r}{T} \arrow[swap]{d}{\rho_V(g)} & W \arrow{d}{\rho_W(g)} \\
  V \arrow{r}{T}& W
  \end{tikzcd}\]
As with any definitions which work with finite-dimensional vector spaces, 
there are equivalent but ``worse'' (as we will have to choose a basis) corresponding 
definitions in terms of matrices. Nonetheless, these definitions with matrices 
are easier computationally and we shall recall the contrast here.

Clearly, if \(G\) is a group and \((\mathbb{C}^n, \rho)\) is a representation, 
we have \(\rho(e) = I_n\). Furthermore, we have a natural isomorphism between 
\(GL_n(\mathbb{C}) \cong GL(\mathbb{C}^n)\) and more generally 
\(\text{Mat}_{n, m}(\mathbb{C}) \cong \text{Hom}(\mathbb{C}^n, \mathbb{C}^m)\).
Similarly, given a representation \((V, \rho)\), with \(\dim V < \infty\), we may 
choose a basis \(B\) of \(V\) and write the representation as a 
matrix which we denote \(\rho^B(g) = [\rho(g)]_B\). Thus, we may use first year 
linear algebra methods to manipulate representations. 

\begin{definition}
  Given two matrix representations \(\rho, \rho' : G \mapsto GL_n(\mathbb{C})\), 
  we say \(\rho\) and \(\rho'\) are equivalent/isomorphic if there exists 
  \(P \in GL_n(\mathbb{C})\) such that for all \(g \in G\), 
  \(\rho'(g) = P^{-1} \rho(g) P\).
\end{definition}
  
This definition is motivated by the following.

\begin{proposition}
  Given \((V, \rho_V)\) and \((W, \rho_W)\) representations of \(G\),
  we have \(\rho_V \cong \rho_W\) if and only if there exists some 
  \(P \in GL_n(\mathbb{C})\) such that for all \(g \in G\), 
  \(\rho_W^C(g) = P^{-1} \rho_V^BP(g) P\) for some basis \(B, C\) of \(V\) and 
  \(W\) respectively.
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

\begin{proposition}
  Given a cyclic group \(C_n = \langle g \rangle\) with representations 
  \((V, \rho_V)\) and \((W, \rho_W)\) of equal dimensions, we have 
  \(\rho_V \cong \rho_W\) if and only if \(\rho_V^B(g)\) is conjugate to 
  \(\rho_W^C(g)\) for some basis \(B, C\) of \(V\) and \(W\) respectively.
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

In fact the proposition above holds for the infinite cyclic group 
\(C_\infty \cong \mathbb{Z}\).

\subsection{Regular Representation}

Let us first recall some definition about group actions though we will omit 
stabilizers, the orbit-stabilizer theorem and transitive actions 
(though it might be helpful to recall them from last year).

\begin{definition}[Group Action]
  Let \(G\) be a group and \(X\) a set, then a group action \((\cdot)\) of 
  \(G\) on \(X\) is a function \(G \times X \to X\) such that for all 
  \(g, h \in G\), \(x \in X\), we have 
  \begin{itemize}
    \item \(g \cdot (h \cdot x) = gh \cdot x\),
    \item \(1 \cdot x = x\).
  \end{itemize}
\end{definition}

Equivalently, a group action can be represented by a group homomorphism between 
\(G\) to \(S_n\) if \(|X| = n < \infty\). We note that there exists an 
bijection between \(\text{Perm}(X)\) (a.k.a \(\text{Aut}(X)\) though we will 
avoid this term in case \(X\) has additional structures) and \(S_n\) with 
depends on a choice of \(X \simeq \{1, \cdots, |X|\}\). 

\begin{definition}[Kernel]
  A kernel of a representation (or group action) is simply the kernel of the 
  corresponding group homomorphism, i.e. if \(\rho\) is a representation 
  (or group action), 
  \[\ker \rho := \{ g \in G \mid \rho(g) = \text{id}\}. \]
  We say a representation (or group action) is faithful if \(\ker \rho = \{e\}\), 
  i.e. \(\rho\) is injective.
\end{definition}

\begin{definition}[Morphism of Group Actions]
  A morphism \(T : X \to Y\) of group actions on \(X\) and \(Y\) is a map 
  such that \(T(g \cdot x) = g \cdot T(x)\) for all \(g \in G\), \(x \in X\).

  This is also called a ``\(G\)-equivariant map'' from \(X\) to \(Y\) and 
  one can see the resemblance of this definition and the definition 
  for homomorphisms between representations.
\end{definition}

For any group \(G\), it acts on itself in three different ways. In particular, 
we have the left regular action \(g \cdot h = gh\), the right regular action 
\(g \cdot h = h g^{-1}\) (where the inverse is required for associativity) 
and the adjoint action \(g \cdot h = g h g^{-1}\). One can see that the left 
and right regular actions are isomorphic via \(T(g) = g^{-1}\). On the other 
hand, they are not isomorphic to the adjoint action (consider 
\(\rho_{\text{ad}}(g)(e) = e\) for all \(g \in G\)).

\begin{proposition}
  Given two actions (or representations) \(\rho, \rho'\) on \(G\), 
  \(g \mapsto \rho(g)\rho'(g)\) is an action (or representation) if and only if 
  \(\rho(g)\rho'(g) = \rho'(g)\rho(g)\), that is \(\rho\) and \(\rho'\) are 
  commuting actions.
\end{proposition}

\begin{definition}
  A subset \(Y \subseteq X\) is said to be stable under an action 
  \((\cdot)\) of \(G\) on \(X\) if \(g \cdot y \in Y\) for all 
  \(y \in Y, g \in G\).
\end{definition}

In the case that \(Y \subseteq X\) is stable, then we may restrict the action 
on \(Y\) to obtain a new action of \(G\) on \(Y\). 

\begin{definition}[Orbit]
  Let \(x \in X\), then \(G \cdot x := \{ g \cdot x \mid g \in G \}\) is called 
  an orbit of \(x\) and we denote this by \(\text{orb}(x)\). 
\end{definition}

It is not difficult to see that orbits are stable and in fact, as an exercise, 
one might show that \(Y \subseteq X\) is stable if and only if it is a union of 
orbits.

In a group \(G\) under the adjoint action, we see that the orbits are the 
conjugacy classes\footnote{What are the orbits of the left action?}. Thus, 
for every conjugacy class, we obtain a action on that class from the adjoint 
action on the whole group. 

\begin{example}
  Let \(G = S_4\) and let \(c = \{(12)(34), (13)(24), (14)(23)\}\). Then 
  as \(c\) is a conjugacy class, we have the adjoint action on \(c\) 
  \[\phi : S_4 \to \text{Perm}(c) \cong S_3.\]
  It is not difficult to show that \(\phi\) is surjective and 
  \(\ker \phi = c \cup \{e\} \cong K_4 \cong C_2 \times C_2\). Thus, 
  by the first isomorphism theorem we have 
  \[S_3 \cong S_4 / K_4.\]
\end{example}

\begin{definition}
  Given a finite set \(X\), let 
  \[\mathbb{C}[X] := \left\{\sum_{x \in X} a_x x \mid a_x 
    \in \mathbb{C}\right\},\]
  equipped with the addition 
  \(\sum_{x \in X} a_x x + \sum_{x \in X} b_x x = 
   \sum_{x \in X} (a_x + b_x) x\) and scalar multiplication 
   \(c \cdot \sum_{x \in X} a_x x = \sum_{x \in X} (c a_x) x\).
  This sum here does not represent some addition operation on \(X\) but a 
  notational trick. One might instead consider elements of \(\mathbb{C}[X]\) 
  as functions \(a : X \to \mathbb{C}\) equipped with point-wise addition and 
  scalar multiplication.
\end{definition}

We observe that \(\mathbb{C}[X] \cong \mathbb{C}^{|X|}\) depending on a 
choice of \(X \cong \{1, \cdots, |X|\}\). Furthermore, we have 
\(X \subseteq \mathbb{C}[X]\) and is a basis (if we interpret \(\mathbb{C}[X]\) 
as a space of functions, the canonical basis is 
\(\{a_x : y \mapsto \chi_{\{x\}} \mid x \in X\}\)). 
In the case that \(X\) is infinite we can still define \(\mathbb{C}[X]\) 
allowing only finite sums.

\begin{proposition}
  If \((\cdot)\) is a group action of \(G\) on \(X\), then,
  the map \((g, \sum a_x x) \mapsto \sum a_x (g \cdot x)\) is a 
  group action of \(G\) on \(\mathbb{C}[X]\).
\end{proposition}

\begin{definition}
  The left regular, right regular, adjoint representations are representations 
  \[\tilde \rho_L, \tilde \rho_R, \tilde \rho_{\text{ad}} :
    G \to GL(\mathbb{C}[G])\] 
  obtained from the left regular, right regular and adjoint actions 
  \[\rho_L, \rho_R, \rho_{\text{ad}} :
    G \to \text{Perm}(G).\] 
\end{definition}

\begin{proposition}
  If \(X\) is any set with a \(G\)-actin, then for all \(g \in G\), 
  \([\rho_{\mathbb{C}[X]}(g)]_B\) is always a permutation matrix.
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

\begin{definition}
  Given \((V, \rho_V), (W, \rho_W)\) representations of \(G\), we denote 
  \[\text{Hom}_G(V, W) := \{T : V \to W \mid G\text{-linear}\}.\]
\end{definition}

\begin{proposition}
  Let \((V, \rho_V)\) be a representation of \(G\) and \(v \in V\). Then, 
  there exists a unique homomorphism of representations 
  \(\mathbb{C}[G] \to V\) where \(\mathbb{C}[G]\) is equipped with the left 
  regular representation such that \(e_G \mapsto v\) and thus, 
  \[\text{Hom}_G(\mathbb{C}[G], V) \cong (V, \rho_V).\]
\end{proposition}
\begin{proof}
  For all \(g \in G\), \(c = \sum_{h \in G} a_h h\), we have 
  \[\begin{split}
    T(g \cdot c) = \rho_V(g)(Tc) 
    & \iff T\left(\sum a_h gh\right) = 
      \rho_V(g)\left(T\left(\sum a_h h\right)\right)\\
    & \iff \sum a_h T(gh) = \sum a_h \rho_V(g)(Th)\\
    & \iff T(gh) = \rho_V(g)(Th), \ \forall h \in G,
  \end{split}\]
  where the second if and only if follows as both \(T\) and \(\rho_V\) 
  are linear. Then choosing \(h = e_G\), we have \(T(g) = \rho_V(g)(v)\) and 
  thus \(T\) is uniquely determined on \(G\) and hence is unique as \(G\) is 
  a basis of \(\mathbb{C}[G]\).
  
  It remains to show that the map \(T\) defined by \(g \mapsto \rho_V(g)(v)\) is 
  a homomorphism of representations. This is clear since 
  \[\begin{split}
    T(g \cdot c) & = T\left(\sum a_h gh\right) = \sum a_h T(gh) \\
      & = \sum a_h \rho_V(gh)(v) = \sum a_h \rho_V(g)(\rho_V(h)(v))\\
      & = \sum a_h \rho_V(g)(Th) = \rho_V(g)\left(T\left(\sum a_h h\right)\right), 
  \end{split}\]
  where the fourth equality follows by the associativity of group actions.
\end{proof}

\subsection{Subrepresentation and Quotient Representation}

\begin{definition}[Subrepresentation]
  A subrepresentation of a representation \((V, \rho_V)\) is a subspace \(W \le V\) 
  such that \(\rho_V(g)(W) \subseteq W\) for all \(g \in G\).
\end{definition}

Clearly, both \(\{0\}\) and \(V\) are subrepresentations of \((V, \rho_V)\), 
and we say a representation is irreducible if these two subrepresentations are 
the only subrepresentations. We say a representation is reducible if it is 
not irreducible. In general, every 1-dimension representation is irreducible.

\begin{proposition}
  Irreducibility is invariant under isomorphisms.
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

\begin{proposition}
  Let \(G\) be finite and \((V, \rho_V)\) is an irreducible representation 
  of \(G\). Then \(\dim V < \infty\).
\end{proposition}
\begin{proof}
  Let \(w \in V \setminus \{0\}\) and let 
  \(W := \text{span}(\{\rho_V(g)(w) \mid g \in G\})\) which is a finite dimensional 
  subrepresentation as \(G\) is finite and for all \(h \in G\), 
  \(\rho_V(h)(\rho_V(g)(w)) = \rho_V(hg)(w)\). Thus, if \(\dim V\) is not finite, 
  we have found a proper subrepresentation which contradicts the irreducibility 
  of \((V, \rho_V)\). 
\end{proof}

\begin{definition}[Quotient Representation]
  For \(W \le V\) a subrepresentation, the quotient representation 
  is \((V / W, \rho_{V / W})\) given by 
  \[\rho_{V / W}(g)(v + W) := \rho_V(g)(v) + W.\]
  This is well-defined as \(W\) is stable under \(\rho_V\).
\end{definition}

\begin{proposition}
  For \(T : (V, \rho_V) \to (W, \rho_W)\) a \(G\)-linear map, \(\ker T\) and 
  \(\text{Im} T\) are subrepresentations.
\end{proposition}
\begin{proof}
  Let \(v \in \ker T\), then \(T(\rho_V(g)(v)) = \rho_W(g)(Tv) = 
  \rho_W(g)(0) = 0\) implying \(\rho_V(g)(v) \in \ker T\) and thus, \(\ker T\) 
  is a subrepresentation. On the other hand, for all \(w \in \text{Im}T\), there 
  exists some \(v \in V\) such that \(Tv = w\). Then \(\rho_W(g)(w) = 
  \rho_W(g)(Tv) = T\rho_W(g)(v)\) implying \(\rho_W(g)(w) \in \text{Im}T\) 
  showing \(\text{Im}T\) is also a subrepresentation.
\end{proof}

\begin{proposition}
  For \(T : (V, \rho_V) \to (W, \rho_W)\) a \(G\)-linear map, we have 
  \[\text{Im} T \cong V / \ker T.\]
\end{proposition}
\begin{proof}
  Follows from the first isomorphism for vector spaces and it remains to check 
  \(V / \ker T \to \text{Im} T\) is \(G\)-linear.
\end{proof}

\begin{proposition}
  If \(T \in \text{End}_G V\) is a \(G\)-linear projection (i.e. \(T^2 = T\)), 
  then \(V\) is a direct sum of subrepresentations \(\ker T \oplus \text{Im} T\).
\end{proposition}
\begin{proof}
  Follows from the vector space case.
\end{proof}

\subsection{Maschke's Theorem and Schur's Lemma}

Recalling internal and external direct sums of vector spaces, we will in this 
section introduce and prove a powerful result in representation theory known as 
the Maschke's theorem.

\begin{definition}[Decomposable]
  The representation \((V, \rho_V)\) is decomposable if there exists a 
  decomposition \(V = U \oplus W\) where \(U, W\) are non-zero subrepresentations.
\end{definition}

\begin{definition}[Semisimple]
  The representation \((V, \rho_V)\) is semisimple if there exists a 
  irreducible subrepresentations \(W_1, \cdots, W_n\) such that 
  \[V = \bigoplus_{i = 1}^n W_i.\]
\end{definition}

\begin{theorem}[Maschke's Theorem]
  If \(G\) is finite, then for all \(W \le V\) subrepresentations of 
  \((V, \rho_V)\), there exists a complementary subrepresentation \(U\), 
  \(V = W \oplus U\). 
\end{theorem}

A direct consequence of Maschke's theorem is that every finite-dimensional 
representation of \(G\) is semisimple.

Maschke's theorem does not hold in the case that \(G\) is not finite. 
Consider \(G = \mathbb{Z}\) and let 
\[\rho : g \to GL_2(\mathbb{C}) : m \mapsto \begin{bmatrix}
  1 & m \\ 0 & 1
\end{bmatrix}.\]
Then the only non-zero proper subrepresentation is \(\text{span}\{e_1\}\) since 
\(e_1\) is the only eigenvector and as \(\rho\) is a 2-dimensional representation, 
the only non-zero proper subrepresentation is 1-dimensional, hence an eigenspace.
Thus, \(\rho\) is indecomposable but not irreducible, and hence not semisimple.

\begin{proof}[Proof of Maschke's Theorem]
  To prove the theorem, we will attempt to find some \(G\)-linear map 
  \(T : V \to V\) that is a projection, i.e. \(T^2 = T\), such that 
  \(\text{im} T = W\) and so \(V = \ker T \oplus \text{Im} T = \ker T \oplus W\).

  In the case of linear maps, a map satisfying the above proposition must map
  \[T(u + w) = Tu + Tw = 0 + w = w,\]
  where \(u \in \ker T\) and \(w \in W\). As, \(\ker T \oplus W = V\), this 
  property uniquely identifies \(T\) on \(V\). However, this map is not 
  \(G\)-linear and so we will modify \(T\) such that it is \(G\)-linear. 
  
  By recalling that a linear map is \(G\)-linear if and only if it is conjugate 
  with it self by \(\rho(g)\) for all \(g \in G\), let us define 
  \[\tilde T := \frac{1}{|G|} \sum_{g \in G} \rho_V(g) \circ T \circ \rho_V(g)^{-1},\]
  such that it is in some sense the average of all conjugates over all \(g\).

  We will now show that \(\tilde T\) is a \(G\)-linear projection and 
  \(\text{im} \tilde T = W\). Indeed, for all \(h \in G\), we have 
  \[\rho_V(h) \circ \frac{1}{|G|} 
    \left(\sum_{g \in G} \rho_V(g) \circ T \circ \rho_V(g)^{-1}\right) \circ
    \rho_V(h)^{-1} = 
    \frac{1}{|G|} \sum_{g \in G} \rho_V(hg) \circ T \circ \rho_V((hg)^{-1})
    = \tilde T,\]
  as \(g \mapsto h \cdot g\) is bijective as it has the inverse 
  \(g \mapsto h^{-1} g\). On the other hand, it is clear that 
  \(\tilde T(V) \subseteq W\) as for all \(v \in V\), \(T(\rho_V(g)^{-1}v) \in W\), 
  and as \(W\) is a subrepresentation, we have \(\rho_V(g)T(\rho_V(g)^{-1}v) \in W\).
  Thus, as \(\tilde T\mid_W = \text{id}\mid_W\), since 
  \[\tilde T w = \frac{1}{|G|} \sum_{g \in G} \rho_V(g)T(\rho_V(g)^{-1}w) = 
    \frac{1}{|G|} \sum_{g \in G} \rho_V(g) \rho_V(g)^{-1} w =
    \frac{1}{|G|} \sum_{g \in G} w = w,\] 
  we have \(\text{Im} \tilde T = W\) and \(\tilde T\) is a projection.
\end{proof}

We note that we used the property of \(\mathbb{C}\) precisely when we needed 
\(|G|^{-1}\) and thus, the same proof works for all field in which \(|G|\) is 
invertible, i.e. of characteristic not a factor of \(|G|\).

This decomposition needs not be unique. Indeed, if \(V, \rho_V\) is a trivial 
representation with dimension \(>1\). Then any vector space decomposition is 
a decomposition of representations. For example, if \(V = \mathbb{C}^2\), 
then 
\[\mathbb{C}^2 = \{(a, 0)\} \oplus \{(0, b)\} = \{(a, a)\} \oplus \{(b, -b)\},\]
and in fact any pair of subspaces spanned by two linearly independent basis 
form a decomposition.

\begin{proposition}
  For \(G = C_m = \langle g \rangle\), \((V, \rho_V)\) a representation of \(G\), 
  there exists a unique decomposition of \((V, \rho_V)\) into 1-dimensional 
  subrepresentations if and only if \(\rho_V(g)\) has distinct eigenvalues.
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

\begin{lemma}[Schur's Lemma]
  Let \(V\) and \(W\) be irreducible representations of \(G\), then 
  \begin{itemize}
    \item every \(G\)-linear map \(T : V \to W\) is invertible or zero;
    \item let \(V = W\) be finite-dimensional, then every \(G\)-linear map 
      \(T : V \to V\) is a multiple of the identity, i.e. 
      \(\text{End}_G V = \mathbb{C} \cdot \text{id}\).
  \end{itemize}
\end{lemma}

We note that the first property does not require \(V, W\) to be finite dimensional,
and in fact it is true for arbitrary fields. On the other hand the second property 
only works for algebraically closed fields. 

\begin{proof}
  The first property is rather trivial. Indeed, if \(T \neq 0\) then \(\ker T\) 
  must be \(\{0\}\) as \(\ker T\) is a subrepresentation and \(V\) is irreducible.
  Similarly, for the same reason \(\text{Im} T = W\) and thus, \(T\) is bijective. 

  For the second property, we recall that the eigenvalues of \(T\) are the roots 
  of the characteristic polynomial of \(T\). Now since \(\mathbb{C}\) is 
  algebraically closed, there exists some \(\lambda \in \mathbb{C}\) such that 
  \(\ker (\lambda I - T) \neq \{0\}\). Now since \(\ker (\lambda I - T)\) is 
  a subrepresentation of \(V\), as \(V\) is irreducible, we have 
  \(\ker (\lambda I - T) = V\). Thus, for all \(v \in V\), 
  \[\lambda v - T v = 0 \implies T v = \lambda v \implies T = \lambda \cdot \text{id}\]
  as required.
\end{proof}

\begin{theorem}
  Up to isomorphism (and reordering), the representation decomposition is unique.
  That is, if \(T : V := V_1 \oplus \cdots \oplus V_m \cong 
    W := W_1 \oplus \cdots \oplus W_n\), 
  then \(V_i \cong W_i\) up to ordering.
\end{theorem}
\begin{proof}
  We have \(T : V \to W\) is a \(G\)-isomorphism map and so \(T(V_i)\) is a 
  subrepresentation of \(W\). Then, as \(W = W_1 \oplus \cdots \oplus W_n\), 
  there exists some \(j\) such that \(W_j \cap T(V_i) \neq \varnothing\). Thus, 
  we have \(T\mid_{V_i} : V_i \to W_j\) is a \(G\)-linear map between two 
  irreducible representations. As \(T\mid_{V_i} \neq 0\), by Schur's lemma, it 
  follows \(T(V_i) = W_i\). Now, since for \(i \neq k\), \(T(V_i) \neq T(V_k)\) 
  as \(T\) is bijective and \(V_i \cap V_k = \varnothing\), by pairing the 
  \(V_i\) and \(W_j\), we are able to correspond each \(V_i\) with a \(W_j\). 
  Reversing this process with \(T^{-1}\), we are able to pair each \(W_j\) with
  a \(V_i\) and thus, we have \(V_i \cong W_i\) up to ordering as required.
\end{proof}

\begin{theorem}
  In the case that \(V\) is finite dimensional, there is a unique decomposition 
  \(V = \bigoplus_{i = 1}^n V_m\) (up to reordering) if and only if in some 
  decomposition, \(V_i\) are all non-isomorphic.
\end{theorem}
\begin{proof}
  Suppose first that \(V_1 \oplus \cdots \oplus V_n = V\), 
  and \(V_1, \cdots, V_n\) are all non-isomorphic. Then, for all \(G\)-linear maps
  \(T : V_i \to V\), we have by a similar argument as above, if \(T \neq 0\), 
  there exists some \(j\) such that \(T : V_i \cong V_j\). But as \(V_i, V_j\) 
  are non-isomorphic for \(i \neq j\), we have \(T \in \text{End}_G V_i\). Thus, 
  by the second part of Schur's lemma, there exists some \(\lambda\) such that 
  \(T = \lambda \cdot \text{id}\mid_{V_i}\). Now, if 
  \(V = W_1 \oplus \cdots \oplus W_m\), by the above theorem, WLOG, we have 
  \(T_i : V_i \cong W_i \subseteq V\). But we just shown 
  \(T_i = \lambda \cdot \text{id}\mid_{V_i}\) and so, \(V_i = W_i\) and the 
  decomposition is unique.

  Conversely, consider that for any representation \(V_i\), there exists infinitely
  many subrepresentations of \(V_i \oplus V_i\) by taking 
  \[V_a := \{(v, av) \mid v \in V\}.\]
  Thus, if \(V_i \cong V_j\), we have
  \[V_a \le V_i \oplus_{ext} V_i \cong V_i \oplus_{ext} V_j \cong V_i \oplus_{int} V_j.\]
  Denoting the isomorphism from \(V_i \oplus_{ext} V_i\) to \(V_i \oplus_{int} V_j\) 
  as \(T\), we have \(T(V_a) \le V_i \oplus_{int} V_j\) and by Maschke's theorem, 
  there exists some subrepresentation \(U\) such that, \(U\) is complement to 
  \(T(V_a)\) and
  \[T(V_a) \oplus_{int} U = V_i \oplus_{int} V_j.\]
  Thus, as \(T\) is an isomorphism, \(a \neq b\) implies \(T(V_a) \neq T(V_b)\), 
  we have found infinitely many non-equal decompositions of \(V_i \oplus_{int} V_j\) 
  and hence, also \(V\).
\end{proof}

\begin{corollary}
  For \(V_1, \cdots, V_n\) irreducible, non-isomorphic, subrepresentations of 
  \(V\) such that \(V = V_1 \oplus \cdots \oplus V_n\) all subrepresentations 
  of \(V\) are of the form \(V_{i_1} \oplus \cdots \oplus V_{i_m}\). In particular 
  \(V\) has \(2^n\) different subrepresentations.
\end{corollary}

\subsubsection{Representation of Abelian Groups}

\begin{definition}[Centre]
  The centre of a group \(G\) is the subgroup with the underlying set 
  \[Z(G) := \{z \in G \mid z g = g z, \forall g \in G\}.\]
\end{definition}

\begin{proposition}
  Let \((V, \rho_V)\) be a finite dimensional irreducible representation and let 
  \(z \in Z(G)\). Then \(\rho_V(z)\) is a scalar, i.e. \(\rho_V(z) = 
  \lambda \cdot \text{id}_V\) for some \(\lambda \in \mathbb{C}\).
\end{proposition}
\begin{proof}
  For all \(g \in G\), we have \(\rho_V(z) \rho_V(g) = \rho_V(zg) = \rho_V(gz) = 
  \rho_V(g) \rho_V(z)\). So \(\rho_V(z) : V \to V\) is \(G\)-linear. Thus, by 
  the second property of Schur's lemma, there exists some \(\lambda\) such that 
  \(\lambda \cdot \text{id}_V\).
\end{proof}

\begin{corollary}
  If \(G\) is abelian and if \((V, \rho_V)\) is an irreducible representation of 
  \(G\), then \(\dim V = 1\).
\end{corollary}
\begin{proof}
  As for abelian groups \(G\), \(Z(G) = G\), we have \(\rho_V(g) = 
  \lambda_g \cdot \text{id}_V\) for all \(g \in G\). Then, for all subspaces \(W\) of 
  \(V\), \(W\) is a subrepresentation. However, as \(V\) is irreducible, 
  \(W\) must either be zero or \(V\), and thus, \(\dim V = 1\).
\end{proof}

\begin{corollary}
  If \(G\) is finite and abelian, then every finite dimensional representation is a 
  direct sum of 1-dimensional subrepresentations.
\end{corollary}

The finite dimensional condition is necessary. Indeed, if \(F\) be a field 
\(C \subsetneq F\) (then \(\dim F = \infty\)), e.g. 
\[F := \left\{\frac{P(X)}{Q(X)} \mid P, Q \in \mathbb{C}[X], Q \neq 0 \right\},\]
then \(F\) is an irreducible \(\infty\)-dimensional representation over \(\mathbb{C}\)
of \(G = F^\times\) although the latter is abelian. 

\begin{corollary}
  The irreducible representations of \(C_m\) are up to isomorphism  
  \((\mathbb{C}, \rho_\zeta)\) where \(\zeta\) is a \(m\)-th root of unity.
  Furthermore, the irreducible representations of \(C_{m_1} \times \cdots \times 
  C_{m_l}\) are up to isomorphism,
  \[\rho_{\zeta_1, \cdots, \zeta_l}(g_1^{j_1}, \cdots, g_l^{j_l}) = 
    (\zeta_1^{j_1}, \cdots, \zeta_l^{j_l}).\]
\end{corollary}

The above corollary is important as every finite abelian group is an internal 
direct product of cyclic groups, we have classified all irreducible representations 
of finite abelian groups. So, if \(G\) is finite abelian, then it has 
\(|G|\) number of 1-dimensional representations.

\begin{proposition}
  Every 1-dimensional representation of a group \(G\) is of the form 
  \((V, \rho_V)\), \(\rho_V(g) = \lambda_g \text{id}_V\) for some 
  \(\lambda_g \in \mathbb{C}\). Furthermore, two such representations are isomorphic 
  if and only if the \(\lambda_g\) are the same.
\end{proposition}
\begin{proof}
  The first statement is clear while the second state follows since, if 
  \((V, \rho_V : g \mapsto \lambda_g \text{id}_V), 
    (W, \rho_W : g \mapsto \lambda'_g \text{id}_W)\) are two isomorphic 
  1-dimensional representations of \(G\) along \(T : V \to W\), then given some 
  \(v \in V \setminus \{0\}\), we have \(T(v) \neq 0\) and
  \[\lambda_g T(v) = T(\lambda_g v) = T(\rho_V(g)(v)) = \rho_W(g)(T(v)) = 
    \lambda_g' T(v).\]
  Thus, \(\lambda_g = \lambda_g'\).
\end{proof}

As all 1-dimensional vector spaces over \(\mathbb{C}\) are isomorphic to 
\(GL_1(\mathbb{C}) \cong \mathbb{C}^\times\), we can simply only consider 
\(\mathbb{C}^\times\) as the vector space of all 1-dimensional representations.

Consider the 1-dimensional representations on \(S_n\). Let \((\mathbb{C}^\times, \rho)\)
be a representation of \(S_n\), then by considering 
\(\sigma(a_1, \cdots, a_n)\sigma^{-1} = (\sigma(a_1), \cdots, \sigma(a_n))\), we 
have 
\[(ij) = ((1i)(2j))(12)((2j)(1i)),\]
and so \((ij)\) is conjugate to \((12)\) for all \(i, j\). Furthermore, by considering 
\(\rho(ij)^2 = \rho((ij)^2) = \rho(e) = \text{id}\), \(\rho(ij) = \pm \text{id}\).
Now, by recalling that 
\(\sigma = \tau \sigma' \tau^{-1} \iff \text{sign}(\sigma) = \text{sign}(\sigma')\), 
and the fact that every permutation can be represented as a product of transpositions, 
either, \(\rho(\sigma) = \text{sign}(\sigma) \cdot \text{id}\) or 
\(\rho(\sigma) = \text{id}\). Thus, there exists exactly two 1-dimensional 
representation up to isomorphism.

\subsection{Abelianisation}

We have so far showed that if \(G\) is abelian, then every finite dimensional 
representation of \(G\) must be 1-dimensional (and in fact, we may drop the 
finite dimensional condition if \(G\) is finite). Now we would like to reduce 
the study of 1-dimensional representations of any group \(G\) to that of an 
abelian group. 

\begin{definition}[Commutator]
  Given a group \(G\), the commutator subgroup is the subgroup \([G, G]\) 
  generated by \([g, h] := ghg^{-1}h^{-1}\) for all \(g, h \in G\).
\end{definition}

\begin{proposition}
  Given a group \(G\), then
  \begin{itemize}
    \item \([G, G] \trianglelefteq G\) (\([G, G]\) is a normal subgroup of \(G\));
    \item \(G / [G, G]\) is abelian;
    \item for a normal subgroup \(N \trianglelefteq G\), \(G / N\) is abelian if 
      and only if \([G, G] \le N\).
  \end{itemize}
\end{proposition}
\begin{proof}
  \hphantom{a}
  \begin{itemize}
    \item For all \(g, h_1, h_2 \in G\), we have 
      \[g [h_1, h_2] g^{-1} = [gh_1 g^{-1}, gh_2 g^{-1}] \in [G, G].\]
    \item Denote \(\overline{g} := g[G, G]\), then 
      \(\overline{g}\overline{h} = gh[G, G]\),
      now since \(h^{-1}g^{-1}hg \in [G, G]\), we have 
      \[\overline{g}\overline{h} = gh[G, G] = gh(h^{-1}g^{-1}hg)[G, G] = 
        hg[G, G] = \overline{h}\overline{g}.\]
    \item If \(G / N\) is abelian, then 
      \[gNhN = hNgN \implies N = gNhNg^{-1}h^{-1}N = ghg^{-1}h^{-1}N,\]
      thus, \(ghg^{-1}h^{-1} \in N\) and so, \([G, G] \le N\).
  \end{itemize}
\end{proof}

\begin{definition}[Abelianisation]
  The abelianisation of a group \(G\) is the abelian group \(G_{ab} := G / [G, G]\).
\end{definition}

We note that as for all normal subgroup \(N\) for which \(G / N\) is 
abelian, we have \([G, G] \trianglelefteq N \trianglelefteq G\), by the third
isomorphism theorem, we have 
\[\frac{G_{ab}}{N / [G, G]} \equiv \frac{G / [G, G]}{N / [G, G]} \cong \frac{G}{N}.\]

\begin{proposition}
  Let \(A\) be an abelian group, the map 
  \[\text{Hom}(G_{ab}, A) \to \text{Hom}(G, A) : \phi \mapsto \phi \circ q_{ab},\]
  is a bijection, where \(q_{ab} : G \mapsto G_{ab}\) is the quotient map. 

  In other words, every homomorphism \(\psi : G \to A\) uniquely corresponds to 
  the homomorphism \(\phi : G_{ab} \to A\) such that \(\psi = \phi \circ q_{ab}\).
\end{proposition}

With this proposition, we see that for all normal subgroups \(N \trianglelefteq G\) 
such that \(G / N\) is abelian, we have the following diagram.
\[\begin{tikzcd}
  G \arrow{r}{q_N} \arrow[swap]{d}{q_{ab}} & G / N \\
  G_{ab} \arrow[swap]{ur}{\exists!}
  \end{tikzcd}\]

\begin{proof}
  Suppose that \(\phi : G \to A\) is a homomorphism, then 
  \(\phi([g, h]) = \phi(ghg^{-1}h^{-1}) = e_A.\), and thus, 
  \([G, G] \le \ker \phi\). Hence, using the universal property of quotient, 
  there exists \[\overline{\phi} : G_{ab} \to A : g[G, G] = \phi(g).\] 
  By construction, \(\overline{\phi} \circ q_{ab} = \phi\), and hence, 
  the map is surjective.

  On the other hand, if \(\phi \circ q_{ab} = \psi \circ q_{ab}\), then for all 
  \(g \in G\), \(\phi(g) = (\phi \circ q_{ab})(g) = (\psi \circ q_{ab})(g) = \psi(g)\) 
  and so \(\phi = \psi\). Thus, the map is bijective as required.
\end{proof}

\begin{corollary}
  If \(|G_{ab}| < \infty\), then the number of 1-dimensional representations of 
  \(G\) equals \(|G_{ab}|\).
\end{corollary}
\begin{proof}
  Follows as the 1-dimensional representations of \(G\) are 
  \(\text{Hom}(G, GL_1(\mathbb{C}))\) which bijects 
  \(\text{Hom}(G_{ab}, GL_1(\mathbb{C}))\), and as \(G_{ab}\) is abelian, 
  it has \(|G_{ab}|\) number of 1-dimensional representations.
\end{proof}

\begin{corollary}
  If \(|G| < \infty\), then the number of 1-dimensional representations of \(G\) 
  divides \(|G|\).
\end{corollary}
\begin{proof}
  Follows as \(|G_{ab}| \mid |G|\) by Lagrange's theorem.
\end{proof}

In some sense we have found a bijection between \(G_{ab}\) and the set 
of 1-dimensional representations of \(G\). However, while \(G_{ab}\) is a group,
the 1-dimensional representations of \(G\) are not. In fact, there is a natural 
group structure on the 1-dimensional representations of \(G\), and for 
\(G_{ab}\) finite, the two groups are isomorphic (exercise).

\begin{proposition}
  If \(G\) is simple nonabelian, then \(G_{ab} = \{e\}\).
\end{proposition}
\begin{proof}
  Clear as the only normal subsgroups of a simple groups are the trivial subgroup 
  or the entire group.
\end{proof}

\begin{definition}[Perfect]
  A group \(G\) is perfect if \([G, G] = G\) (or equivalently \(G_{ab} = \{e\}\)).
\end{definition}

From the above proposition, we see that simple nonabelian implies perfect. 
Furthermore, \(G\) is perfect implies all 1-dimensional representations of \(G\) 
are trivial. In the case the \(G\) is finite, the converse is also true.

\subsection{Decomposition of Representations}

\subsubsection{Regular Representation}

Recall that for linear maps, the space of all linear maps between two vector 
spaces form a linear map and we have the following isomorphisms.

\begin{lemma}
  \[\text{Hom}(V, W_1 \oplus W_2) \cong \text{Hom}(V, W_1) \oplus \text{Hom}(V, W_2),\]
  and similarly,
  \[\text{Hom}(V_1 \oplus V_2, W) \cong \text{Hom}(V_1, W) \oplus \text{Hom}(V_2, W).\]
\end{lemma}
\begin{proof}
  Clear using the natural bijections.
\end{proof}

Similarly to the situation for vector spaces, the space of representations also 
form a vector space and similar isomorphisms hold. In particular, 
\[\text{Hom}_G(V, W_1 \oplus W_2) \cong \text{Hom}_G(V, W_1) \oplus \text{Hom}_G(V, W_2),\]
and
\[\text{Hom}_G(V_1 \oplus V_2, W) \cong \text{Hom}_G(V_1, W) \oplus \text{Hom}_G(V_2, W),\]
where the space \((\text{Hom}_G(V, W), \rho_{\text{Hom}(V, W)})\) is defined such 
that 
\[\rho_{\text{Hom}(V, W)}(g)(\phi) = \rho_W(g) \circ \rho \circ \rho_V(g)^{-1}.\]

If \(G\) is finite, By Maschke's theorem, \(\mathbb{C}[G]\) is finite dimensional, 
and so, \(\mathbb{C}[G]\) is always decomposable into irreducible representations. 
We will now prove some properties about this decomposition.

\begin{proposition}
  Let \(V_1, \cdots, V_m\) be irreducible representations that are 
  non-isomorphic such that 
  \[\mathbb{C}[G] \cong V_1^{r_1} \oplus \cdots \oplus V_m^{r_m},\]
  where \(W^k = W \oplus \cdots \oplus W\) \(k\)-times. Then, \(\dim V_i = r_i\).
\end{proposition}
\begin{proof}
  Recall that \(\text{Hom}_G(\mathbb{C}[G], V) \cong V\) by the bijection 
  \(\phi \mapsto \phi(e)\). So, by this and the above isomorphism,
  \[V_i \cong \text{Hom}_G(\mathbb{C}[G], V_i) \cong 
    \bigoplus_{j = 1}^m \text{Hom}_G(V_j, V_i)^{r_j}.\]
  By Schur's lemma, for all \(i \neq j\), we have \(\text{Hom}_G(V_i, V_j) = 0\) 
  and so,
  \[\bigoplus_{j = 1}^m \text{Hom}_G(V_j, V_i)^{r_j} \cong 
    (\mathbb{C} \cdot \text{Id}_{V_i})^{r_i} \cong \mathbb{C}^{r_i}.\]
  Thus, we have \(\dim V_i = r_i\).
\end{proof}

\begin{corollary}
  Let \(V_1, \cdots, V_m\) be irreducible representations that are 
  non-isomorphic such that 
  \[\mathbb{C}[G] \cong V_1^{r_1} \oplus \cdots \oplus V_m^{r_m}.\]
  Then, \(r_i = 1\) for all \(i\) if \(G\) is abelian.
\end{corollary}

As we shall see, converse is also true.

\begin{corollary}
  Let \(V_1, \cdots, V_m\) be irreducible representations that are 
  non-isomorphic such that 
  \[\mathbb{C}[G] \cong V_1^{r_1} \oplus \cdots \oplus V_m^{r_m},\]
  then 
  \[|G| = \sum_{i = 1}^m (\dim V_i)^2.\]
\end{corollary}
\begin{proof}
  \[|G| = \dim \mathbb{C}[G] = \dim (V_1^{r_1} \oplus \cdots \oplus V_m^{r_m}) 
    = \dim (V_1^{\dim V_1} \oplus \cdots \oplus V_m^{\dim V_m}) 
    = \sum_{i = 1}^m (\dim V_i)^2.\]
\end{proof}

This is the sum of squares formula though it provided that 
every irreducible representation of \(G\) is isomorphic to exactly one of the
\(V_i\).

\begin{proposition}
  Let \(V_1, \cdots, V_m\) be irreducible representations that are 
  non-isomorphic such that 
  \[\mathbb{C}[G] \cong V_1^{r_1} \oplus \cdots \oplus V_m^{r_m}.\]
  Then for all irreducible representations \(W\) of \(G\), there exists uniquely 
  \(i\) such that \(W \cong V_i\).
\end{proposition}
\begin{proof}
  By assumption \(V_i \not\cong V_j\) for \(i \neq j\) and so, it remains to 
  show \(W\) must be isomorphic at some \(V_i\). Suppose otherwise, 
  then, 
  \[W \cong \text{Hom}_G(\mathbb{C}[G], W) \cong \bigoplus_i 
    \text{Hom}_G(V_i, W) = 0,\]
  by Schur's lemma, which is a contradiction.
\end{proof}

\begin{corollary}
  For non-trivial \(G\), every irreducible representation has dimension strictly 
  less than \(\sqrt{|G|}\).
\end{corollary}
\begin{proof}
  Given \((V, \rho)\) a non-trivial representation,
  \[|G| = \dim \mathbb{C}[G] = \dim (\mathbb{C} \oplus V^{\dim V} \oplus \cdots) 
    \ge \dim (\mathbb{C} \oplus V^{\dim V}) = 1 + (\dim V)^2.\]
\end{proof}

\subsubsection{Revisiting Maschke's Theorem}

\begin{definition}[\(G\)-invariant Subspace]
  Given a representation \((V, \rho_V)\) of \(g\), then the \(G\)-invariant subspace 
  of \(V\) is 
  \[V^G := \{v \in V \mid \rho_V(g)(v) = v, \ \forall g \in G\}.\]
\end{definition}

A useful note is that, \(V^G\) is the intersection of all eigenspaces of 
\(\rho_V(g)\) of eigenvalue 1 for all \(g\).

\begin{lemma}
  \(V^G \subseteq V\) is the largest trivial subrepresentation of \(V\). 
\end{lemma}
\begin{proof}
  \(V^G\) is a trivial subrepresentation as it sends every element of \(V^G\) 
  to itself and thus, \(\rho_{V^G}(g) = \text{Id}_{V^G}\) for all \(g \in G\). 
  Lastly, if \(W \subseteq V\) is a trivial subrepresentation, for all \(v \in W\), 
  \(\rho_W(g)(v) = \text{Id}_W v = v\) for all \(g \in G\), and so 
  \(v \in V^G\) and hence, \(W \subseteq V^G\).
\end{proof}

\begin{definition}[Averaging Map]
  If \(G\) is finite and \((V, \rho_V)\) is a representation of \(G\), then 
  the averaging map is the function 
  \[\text{avg} : V \to V : v \mapsto \frac{1}{|G|} \sum_{g \in G} \rho_V(g)(v).\]
\end{definition}

\begin{proposition}
  The averaging map is a \(G\)-linear projection with the image \(V^G\).
\end{proposition}
\begin{proof}
  Clearly, \(\text{Im}(\text{avg}) \subseteq V^G\) since for all \(h \in G\), 
  \(v \in V\),
  \[\rho(h)(\text{avg}(v)) = 
    \rho(h)\left(\frac{1}{|G|}\sum_{g \in G}\rho(g)(v)\right) = 
    \frac{1}{|G|}\sum_{g \in G}\rho(hg)(v) = 
    \frac{1}{|G|}\sum_{g \in G}\rho(g)(v) = \text{avg}(v).\]
  Furthermore, as \(\text{avg}\mid_{V^G} = \text{Id}_{V^G}\), we have 
  \(\text{Im}(\text{avg}) = V^G\) and thus, \(\text{avg}\) is a projection.
  Finally, by the same calculation, we have 
  \[\rho(h)(\text{avg}(v)) = 
    \frac{1}{|G|}\sum_{g \in G}\rho(hg)(v) =
    \frac{1}{|G|}\sum_{g \in G}\rho(gh)(v) = 
    \frac{1}{|G|}\sum_{g \in G}\rho(g)(\rho(h)(v)) = \text{avg}(\rho(h)(v)),\]
  which shows \(\text{avg}\) is a \(G\)-linear map.
\end{proof}

With this proposition, we obtain that \(V = \ker(\text{avg}) \oplus V^G\) with 
\(\ker(\text{avg})\) being a subrepresentation with no \(G\)-invariant vectors, 
i.e. \(\ker(\text{avg})^G = \{0\}\). With these definitions in mind, let us 
revisit Maschke's theorem.

\begin{proposition}
  \(\text{Hom}_G(V, W) = \text{Hom}(V, W)^G\).
\end{proposition}
\begin{proof}
  Definition check.
\end{proof}

\begin{corollary}
  The map 
  \[\text{avg} : \text{Hom}(V, W) \to \text{Hom}(V, W)^G = \text{Hom}_G(V, W)\]
  is a \(G\)-linear projection.
\end{corollary}

Thus, with this corollary, we see that the averaging map provides a (\(G\)-linear) 
map between \(\text{End}(V)\) and \(\text{End}_G(W)\). Nonetheless, to obtain 
Maschke's theorem, it remains to show that it \(\text{avg}\) maps 
linear projections to \(G\)-linear projections (with the same image).

\subsubsection{Adjoint Representation}

Consider \(V_1, \cdots, V_m\) be all irreducible representations 
(up to isomorphism) of \(G\) with \(|G|\). Then, we may define the map 
\[G \to \bigoplus_{i = 1}^m\text{End}(V_i) : g \mapsto 
  (\rho_{V_1}(g), \cdots, \rho_{V_m}(g)).\]
Linearly extending, we obtain a map \(\phi : \mathbb{C}[G] \to \bigoplus 
\text{End}(V_i)\). Then, by the sum of squares formula, since 
\(\dim(\text{End}(W)) = (\dim W)^2\), the source and target of \(\phi\) have 
the same dimension.

\begin{proposition}
  The map \(\phi : \mathbb{C}[G] \to \bigoplus \text{End}(V_i)\) is a 
  linear isomorphism and is \(G\)-linear with respect to the adjoint 
  representation.
\end{proposition}
\begin{proof}
  It suffices to show \(G\)-linearity. For all \(h \in G\), we have 
  \[\begin{split}
    \phi(\rho_{ad}(g)(h)) & = \phi(ghg^{-1}) = 
    (\rho_{V_1}(ghg^{-1}), \cdots, \rho_{V_m}(ghg^{-1}))\\
    & = (\rho_{\text{End}(V_1)}(g)(\rho_{V_1}(h)), \cdots, 
      \rho_{\text{End}(V_m)}(g)(\rho_{V_m}(h)))\\
    & = \rho(g)(\phi(h)).
  \end{split}\]
\end{proof}

Thus, we have found found an isomorphism 
\(\mathbb{C}[G]_{ad} \cong \bigoplus \text{End}(V_i)\) and thus, taking the 
dimension of both sides, we recover the sum of squares formula 
\(|G| = \sum \dim(V_i)^2\). In particular, we have replaced an equality by an 
isomorphism and in general, this process is called ``categorification''.

Continuing with \(V_1, \cdots, V_m\) as the irreducible representations of 
\(G\), \(|G| < \infty\) up to isomorphism, we have the following corollaries.

\begin{corollary}
  Since,
  \[\mathbb{C}[G]_{ad} \cong \bigoplus_{i = 1}^m \text{End}(V_i).\]
  By taking \(G\)-invariant subspaces, we have 
  \[\mathbb{C}[G]_{ad}^G \cong \bigoplus_{i = 1}^m \text{End}(V_i)^G = 
  \bigoplus \text{End}_G(V_i) = \bigoplus \mathbb{C} \cdot \text{Id}_{V_i} 
  \cong \mathbb{C}^m\]
  by Schur's lemma. 
\end{corollary}

\begin{proposition}
  \((\mathbb{C}[G], \rho_{ad})^G\) have a basis \(f_1, \cdots, f_{m'}\) given 
  by 
  \[f_i = \sum_{g \in \mathcal{C_i}}g,\]
  where \(\mathcal{C}_1, \cdots, \mathcal{C}_{m'}\) are the conjugacy classes 
  of \(G\).
\end{proposition}
\begin{proof}
  Follows by considering \(\sum a_g g \in \mathbb{C}[G]_{ad}^G \iff a_h = a_{ghg^{-1}}\) 
  for all \(g, h \in G\).
\end{proof}

\begin{corollary}
  The number of conjugacy classes of \(G\) equals the number of irreducible 
  representation up to isomorphisms.
\end{corollary}
\begin{proof}
  Follows by taking the dimensions on both sides of the isomorphism 
  \(\mathbb{C}[G]_{ad}^G \cong \mathbb{C}^m\).
\end{proof}

\subsection{Tensor Product and Dual Representations}

We will in the section recall tensor product of vector spaces and extend the 
notion of tensor products to representations.

\subsubsection{Tensor Product of Vector Spaces}

In essence, similar to direct sums, the tensor product of two vector spaces 
in some sense combine them into a larger vector space. In particular, 
while (external) direct sums ``glue'' the vectors of the two spaces, the tensor 
product combined the coefficients of each vectors of the two spaces pairwise.

\begin{definition}[Free Vector Space]
  Let \(S\) be a set and \(\mathbb{F}\) be a field. Then the 
  \(\mathbb{F}\)-free vector space over \(S\) is the set given by 
  \[\mathbb{F}[S] := \left\{ \sum_{s \in S} a_s s \mid 
    |\text{supp}(a)| < \infty \right\}.\]
\end{definition}
We note that we have already seen this definition in the context of monoid 
algebras. The free vector space is equipped with the natural notion of 
addition and scalar multiplication and forms a vector space over \(\mathbb{F}\).

Again, \(s \in S\) corresponds to the elements of the free vector space 
with coefficients \(a_s = 1\) and \(a_r = 0\) for all \(r \neq s\), and in that 
sense, \(S\) is a basis of \(\mathbb{F}[S]\). Thus, with this definition, 
we may consider the free vector space of \(V \times W\). It is clear that 
\(\mathbb{F}[V \times W]\) has a basis of \(V \times W\), and so 
\(\mathbb{F}[V \times W]\) is huge in the sense that
\[\dim \mathbb{F}[V \times W] = |V \times W|.\]
In some sense, the construction of the free vector space forgets the vector 
space structure of \(V\) and \(W\) (am I correct in saying it is a forgetful 
functor?). In particular, we note that for \(v_1, v_2 \in V, w \in W\), 
\((v_1, w) +_{\mathbb{F}[V \times W]} (v_2, w)\) corresponds to the function 
which maps \((v_1, w)\) and \((v_2, w)\) to 1 and 0 otherwise, and thus, 
\((v_1, w) +_{\mathbb{F}[V \times W]} (v_2, w) \neq (v_1 + v_2, w)\). 

This, is however not what we want and so we will quotient it by some subspace.

\begin{definition}[Tensor Product]
  Let \(V, W\) be vector spaces over the field \(\mathbb{F}\) and define 
  \(B(V \times W)\) a subspace of \(\mathbb{F}[V \times W]\) by 
  \[\begin{split}
    B(V \times W) = \text{span}\{& (v_1 + v_2, w) - (v_1, w) - (v_2, w); \\
      & (v, w_1 + w_2) - (v, w_1) - (v, w_2); \\
      & (\lambda v, w) - \lambda(v, w); \\
      & (v, \lambda w) - \lambda(v, w) \mid 
      v, v_1, v_2 \in V, w, w_1, w_2 \in W, \lambda \in \mathbb{F}\}.
  \end{split}\]
  Then the tensor product \(V \otimes W\) is simply 
  \[V \otimes W = \mathbb{F}[V \times W] / B(V \times W).\]
\end{definition}

We denote the image of \((v, w) \in \mathbb{F}[V \times W]\) under the quotient 
map \(\mathbb{F}[V \times W] \to V \otimes W\) by \(v \otimes w\).

\begin{proposition}
  For \(V, W\) vector spaces over the field \(\mathbb{F}\),
  for all \(v, v_1, v_2 \in V, w, w_1, w_2 \in W, \lambda \in \mathbb{F}\), 
  we have 
  \begin{itemize}
    \item \((v_1 + v_2) \otimes w = v_1 \otimes w + v_2 \otimes w\); 
    \item \(v \otimes (w_1 + w_2) = v \otimes w_1 + v \otimes w_2\); 
    \item \((\lambda v) \otimes w = \lambda(v \otimes w)\); 
    \item \(v \otimes (\lambda w) - \lambda(v \otimes w)\).
  \end{itemize}
\end{proposition}
\begin{proof}
  By definition of the quotient.
\end{proof}

\begin{theorem}[Universal Property]
  Let \(V, W, Z\) be vector spaces, then there exists a bilinear map 
  \(F : V \times W \to V \otimes W\) such that for all bilinear maps 
  \(\alpha : V \times W \to Z\), there exists a unique linear map 
  \(\tilde \alpha : V \otimes W \to Z\) such that 
  \(\alpha = \tilde \alpha \circ F\).
\end{theorem}
\begin{proof}
  Let \(\alpha\) be a bilinear map, and we can define \(\bar \alpha\) as the 
  linear extension of \(\alpha\) such that 
  \[\bar \alpha : \mathbb{F}[V \times W] \to Z : 
  \sum_{i = 1}^n a_i (v_i, w_i) \mapsto \sum_{i = 1}^n a_i \alpha(v_i, w_i).\]
  Since \(\alpha\) is bilinear, we have \(B(V \times W) \subseteq \ker \bar \alpha\).
  Thus, by the universal property of the quotient, there exists a unique  
  \(\tilde \alpha : V \otimes W \to Z\) such that 
  \(\tilde \alpha \circ q = \bar \alpha\). 
\end{proof}

One might imagine the universal property as the following 
commutating diagram.
\[\begin{tikzcd}
  V \times W \arrow{r}{\alpha} \arrow[swap]{d}{F} & Z \\
  V \otimes W \arrow[swap]{ur}{\tilde \alpha}&
  \end{tikzcd}\]
In paricular, we have the diagram 
\[\begin{tikzcd}
  V \times W \arrow[hookrightarrow]{r}{\iota} \arrow[swap]{rd}{\alpha}
    & \mathbb{F}[V \times W] \arrow{r}{q} \arrow{d}{\bar \alpha} 
    & V \otimes W \arrow{ld}{\tilde \alpha}\\
  & Z &
\end{tikzcd}\]
and so we may simply \(F = q \circ \iota\) which is bilinear.

Thus, with the universal property, we have obtained a bijection between 
the set of bilinear maps from \(V \times W \to Z\) and the set of linear 
maps between \(V \otimes W \to Z\).

\begin{proposition}
  The universal property determines \(V \otimes W\) uniquely up to isomorphism, 
  i.e. if \(Z\) is a vector space satisfying the universal property of 
  \(V \otimes W\), then \(Z \cong V \otimes W\).
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

\begin{proposition}
  Let \((v_i)_{i \in I}\) be a basis of \(V\), and \((w_j)_{j \in J}\) be a basis 
  of \(W\). Then, \((v_i \otimes w_j)_{i \in I, j \in J}\) is a basis of 
  \(V \otimes W\).
\end{proposition}
\begin{proof}
  Exercise (Hint: to show linear independence, consider the bilinear map 
  \(B_{nk} : V \times W \to \mathbb{F} : 
  \left(\sum \lambda_i v_i, \sum \mu_j w_j\right) \mapsto \lambda_n \mu_k\) 
  for all \(n, k\)). 
\end{proof}

\begin{proposition}
  There is a canonical linear injection 
  \[V^* \otimes W \to \text{Hom}(V, W),\]
  and this is an isomorphism if \(V\) is finite dimensional.
\end{proposition}
\begin{proof}
  Define 
  \[T : V^* \times W \to \text{Hom}(V, W) : (f, w) \mapsto (v \mapsto f(v)w).\]
  It is easy to see that \(T\) is bilinear and so, by the universal property, 
  there exists a unique linear map \(\tilde T : V^* \otimes W \to \text{Hom}(V, W)\) 
  such that \(\tilde T(f \otimes w) = T(f, w)\). Now, if 
  \(f \otimes w \in \ker \tilde T\), we have either \(f = 0\) or \(w = 0\), and 
  so \(f \otimes w = 0\). Thus, \(\ker \tilde T = \{0\}\) and hence, it is an 
  injection.

  In the case that \(V\) is finite dimensional, we have 
  \[\dim (V^* \otimes W) = \dim V^* \dim W = \dim V \dim W = \dim(\text{Hom}(V, W)),\]
  and so \(T\) is an isomorphism by a dimensional argument.
\end{proof}

\begin{corollary}
  For \(V\) finite dimensional, we have
  \[V \otimes W \cong V^{**} \otimes W \cong \text{Hom}(V^*, W).\]
\end{corollary}

\begin{proposition}
  \(\mathbb{F} \otimes W \cong W\).
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

\begin{lemma}\label{tensor_map}
  Given linear maps \(T_1 : V \to U_1, T_2 : W \to U_2\), we have 
  \[T_1 \otimes T_2 : V \otimes W \to U_1 \otimes U_2 : 
    v \otimes w \mapsto T_1(v) \otimes T_2(w),\]
  is a linear map. Furthermore, if \(T_i, S_i\) for \(i = 1, 2\) 
  are linear maps on appropriate domains and codomains, 
  \[(T_1 \otimes T_2) \circ (S_1 \otimes S_2) = 
    (T_1 \circ S_1) \otimes (T_2 \circ S_2).\]
\end{lemma}
\begin{proof}
  Easy checks using the universal property.
\end{proof}

\subsubsection{Tensor Product of Representations}

In representation theory, we may also consider the tensor product of 
representations. In particular, if \((V, \rho_V)\) and \((W, \rho_W)\) are 
representations, then we define 
\[(V \otimes W, \rho_{V \otimes W} := g \mapsto \rho_V(g) \otimes \rho_W(g)),\]
to be the tensor product of the representations. We note that 
\(\rho_V(g) \otimes \rho_W(g) \in GL(V \otimes W)\) for all 
\(g\) by lemma \ref{tensor_map} and so the representation is well-defined. 

In the case that \(V = \mathbb{C}\), we have the representation 
\(\rho_V : G \mapsto GL_1(\mathbb{C}) \cong \mathbb{C}^\times\) is simply a 
multiplication by some scalar \(\rho \neq 0\). Thus, 
\(\rho_{\mathbb{C} \otimes W}(g) = \rho \rho_W(g)\), and 
\[(\mathbb{C} \otimes W, \rho_{\mathbb{C} \otimes W}) \cong (W, \rho \rho_W).\]
Furthermore, if \(W = \mathbb{C}\) as well, then we have 
\((\mathbb{C}, \rho \otimes \rho') \cong (\mathbb{C}, \rho\rho')\).  

\textbf{N.B. omitted some exercises which I'm confused about.}

\begin{definition}[Dual Representation]
  Given a representation \((V, \rho_V)\), we define the dual representation 
  to be the representation \((V^*, \rho_{V^*})\) where \(V^*\) is the dual space 
  of \(V\) and 
  \[\rho_{V^*}(g)(\phi) = \phi \circ \rho_V(g)^{-1},\]
  for all \(\phi \in V^*\), \(g \in G\).
\end{definition}

We note that the inverse in the definition is required since 
\[\rho_{V^*}(gh)(\phi) = \rho_{V^*}(g) \circ \rho_{V^*}(h)(\phi) = 
  \phi \circ \rho_V(h^{-1}) \circ \rho_V(g^{-1}) = 
  \phi \circ \rho_V(h^{-1}g^{-1}) = \phi \circ \rho_V(gh)^{-1}.\]

In the case we are working with finite dimensional representations, given a 
basis \(B = \{v_1, \cdots, v_n\}\) of \(V\), we have a 
dual basis \(D = \{f_1, \cdots, f_n\}\) of \(V^*\) given by 
\(f_i(v_j) = \delta_{ij}\). Then, the \((j, i)\)-th entry of 
\([\rho_{V^*}(g)]_D\) is 
\[\rho_{V^*}(g)(f_i)(v_j) = f_i(\rho_V(g^{-1})(v_j)).\]
On the other hand, the \((i, j)\)-th entry of \([\rho_V(g^{-1})]_B\) is 
\(f_i(\rho_V(g^{-1})(v_j))\) and so, 
\[[\rho_{V^*}(g)]_D = [\rho_V(g^{-1})]_B^T =  ([\rho_V(g)]_B^{-1})^T.\]

A similar relation can be established for the matrix form of the tensor 
product. Let \(B = \{v_1, \cdots, v_m\}\) be a basis of \(V\) and 
\(C = \{w_1, \cdots, w_n\}\) be a basis of \(W\). Then, 
\(D := \{v_i \otimes w_j\}\) form a basis of \(V \otimes W\). Let \(g \in G\) 
and \(M := [\rho_V(g)]_B\), \(N = [\rho_W(g)]_C\). Then, 
\[\begin{split}
  \rho_{V \otimes W}(g)(v_k \otimes w_l) 
  & = \rho_V(g)(v_k) \otimes \rho_W(g)(w_l) 
    = \sum_i M_{ik}v_i \otimes \sum_j N_{jl}w_j\\
  & = \sum_{i, j} M_{ik}v_i \otimes N_{jl}w_j
    = \sum_{i, j} M_{ik}N_{jl} v_i \otimes w_j.
\end{split}\]
Thus, the matrix representation of \(\rho_{V \otimes W}(g)\) is 
\[[\rho_{V \otimes W}(g)]_{B \otimes C} = [M_{ik}N_{jl}]_{(i, j), (k, l)}.\]
Note that the rows are indexed by pairs \((i, j) \in I \times J\) and the 
columns by \((k, l) \in I \times J\). 

This matrix operation is known as the Kronecker product, in particular, the 
Kronecker product of matrices \([a_{ik}]\) and \([b_{jl}]\) is
\[[a_{ik}] \otimes [b_{jl}] := [a_{ik}b_{jl}]_{(i, j), (k, l)}.\]

\subsubsection{External Tensor Product}

So far we have seen methods of constructing new representations of \(G\) 
using existing representations of \(G\) with the tensor product. It turns 
out this procedure can be applied to smaller groups to obtain representations 
on ta larger group.

Given \((V, \rho_V), (W, \rho_W)\) representations of \(G\), we note that 
\(V \otimes W\) actually provides a representation of \(G \times G\) by 
taking \(\rho_V(g) \otimes \rho_W(h)\) for \((g, h) \in G \times G\). 
Let us denote this representation by \(\rho_{V \boxtimes W}\).

\begin{definition}[External Tensor Product]
  Let \((V, \rho_V)\) be a representation of \(G\) and \((W, \rho_W)\) be a 
  representation of \(H\). Then \((V \otimes W, \rho_{V \boxtimes W})\) is a 
  representation of \(G \times H\) where 
  \[\rho_{V \boxtimes W}(g, h) = \rho_V(g) \otimes \rho_W(h).\]
\end{definition}

\begin{proposition}
  \((V \otimes W, \rho_{V \boxtimes W})\) is irreducible if and only if 
  \(V\) and \(W\) are irreducible. Furthermore, if \(G\) and \(H\) are finite, 
  these are the only irreducible representations of \(G \times H\) up to 
  isomorphism.
\end{proposition}
\begin{proof}
  Omitted.
\end{proof}

\newpage
\section{Restriction and Coinduction}

We have already used the following definition though it is useful to introduce 
a notation for it. 

\begin{definition}[Resetricted Representation]
  Given a subgroup \(H < G\) and a representation \((V, \rho_V)\) of \(G\), 
  the restricted representation \(\text{Res}_H^G(V)\) is the representation 
  of \(H\) defined by \((V, \rho_v \circ i)\) where \(i\) is the inclusion map 
  from \(H\) to \(G\).
\end{definition}

As the underlying vector space remains the same, we have 
\(\dim V = \dim \text{Res}_H^G(V)\).

Conversely, we would like to obtain a representation of \(G\) from a 
representation of \(H\). This process is known as induction and the resulting 
representation is called the (co)induced representation.

\begin{definition}[Coinduced Representation]
  Let \(H < G\) be a subgroup and \((V, \rho_V)\) be a representation of \(H\). 
  Then, the coinduced representation \(\text{coInd}_H^G(V)\) is defined as 
  \[\text{coInd}_H^G(V) := \{f : G \to V \mid f(hg) = \rho_V(h)f(g), \ 
    \forall g \in G, h \in H\},\]
  with the action of \(G\) given by \((g \cdot \phi)(g') := \phi(g'g)\).
\end{definition}

We see that \(\text{coInd}_H^G(V)\) are functions from \(G\) to \(V\) which are 
\(H\)-invariant. Equivalently, the coinduced representation can be defined 
by \(\text{coInd}_H^G(V) = \text{Hom}_H(\mathbb{C}[G], V)\). Unlike the 
restricted representation, the coinduced representation does not fix the 
dimension.

\begin{proposition}
  Denoting \(H \setminus G\) the set of right cosets of \(H\) in \(G\), the map 
  \[\Psi : \text{Fun}(H \setminus G, V) \to \text{coInd}_H^G(V) : 
    \phi \mapsto (hg_i \mapsto \rho_V(h)\phi(Hg_i))\]
  is a linear isomorphism.
\end{proposition}
\begin{proof}
  Definition check.
\end{proof}

\begin{corollary}
  Let \([G : H]\) be the index of the subgroup \(H\), then 
  \[\dim \text{coInd}_H^G(V) = [G : H]\dim V.\]
\end{corollary}
\begin{proof}
  If \([G : H] = \infty\) then both sides of the equation are infinite. 
  Suppose that \([G : H] = n < \infty\), then by the above isomorphism, 
  we have \(\dim \text{coInd}_H^G(V) = \dim \text{Fun}(H \setminus G, V) = 
  \dim V^n = [G : H] \dim V\).
\end{proof}

\begin{definition}
  Let \(X\) be a nonempty set and let \(x \in X\). Then we define 
  \(V(x) \subseteq \text{Fun}(X, V)\) be the subspace of functions which have 
  value zero on every element of \(X\) except \(x\). 
\end{definition}

\begin{proposition}
  \(V(x) \cong V\), \(\bigoplus_{x \in X} V(x) \subseteq \text{Fun}(X, V)\) which 
  becomes an equality for \(X\) finite, and \(\text{Fun}(X, V) \cong V^{|X|}\).
\end{proposition}

\newpage 
\section{Character Theory}

Character theory is the study of the traces of finite dimensional representations.
In particular, character theory study the representations by forgetting the 
vector space themselves. To support this, we observe that the trace function 
is invariant under isomorphisms and thus, will play a fundamental role 
in our definitions. 

\begin{definition}[Character]
  The character of a representation \((V, \rho : G \to V)\) is 
  the function \(\chi_\rho : G \to \mathbb{C} : g \mapsto \text{tr}(\rho(g))\). 

  When there is no confusion, we write \(\chi_V\) for \(\chi_{\rho_V}\).
\end{definition}

We recall to that the trace defined on general finite dimensional vector spaces 
can be found by making a choice of basis and finding the trace of the specific 
matrix representation. As the trace is independent of the choice of basis, 
this definition is well-defined. 

This definition however is inelegant as we were required to make a choice of basis. 
The choice can be avoided by observing that \(\text{Hom}(V, V) \cong V^* \otimes V\), 
and there exists a natural map 
\[V^* \otimes V \to \mathbb{C} : f \otimes v \mapsto f(v).\]
Then, composing the two maps, one can show that this is indeed the trace function.

\begin{proposition}
  If \(G\) is a finite group, then given \((V, \rho_V), (W, \rho_W)\) representations 
  of \(G\), we have \(\chi_{\rho_V} = \chi_{\rho_W}\) if and only if 
  \((V, \rho_V) \cong (W, \rho_W)\).
\end{proposition}
\begin{proof}
  The backward direction is trivial by choosing a basis while the backwards direction 
  will be proved later in the course.
\end{proof}

Thus, classifying characters will also classify representations up to isomorphism.

\begin{proposition}
  The character of the permutation representation maps \(g\) to the number of 
  fixed points of \(g\).
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

\subsection{Class Function}

\begin{definition}[Class Function]
  A class function \(f : G \to \mathbb{C}\) is a function such that 
  \(f(ghg^{-1}) = f(h)\) for all \(g, h \in G\). 

  We denote \(\text{Fun}_{cl}(G, \mathbb{C}) \subseteq \mathbb{C}^G = 
    G \to \mathbb{C}\) the set of class functions.

  We observe that if we quotient \(G\) by the equivalence relation of conjugacy
  (note that this quotient is not a group), the class function is a function 
  satisfying the universal property of this quotient.
\end{definition}

As remarked in the definition of the free vector space, the set of functions 
from \(X \to \mathbb{C}\) is closely related to the free vector space 
\(\mathbb{C}[X]\). In particular, we have the embedding 
\[\sum a_x x \mapsto (x \mapsto a_x) : \mathbb{C}[X] \to \mathbb{C}^X,\]
and in the case that \(X\) is finite, this map is an isomorphism.

Recall that given a group action \(G \times X \to X\), we may extend this 
linearly to become a group representation of \(G\) with 
\((\mathbb{C}[X], \rho_{\mathbb{C}[X]})\). A similar process can be applied 
to \(\mathbb{C}^X\) by defining 
\[g \cdot f \mapsto (x \mapsto f(g^{-1} \cdot x)) : 
  G \times \mathbb{C}^X \to \mathbb{C}^X.\]
We note that the inverse is required since for \(g_1, g_2 \in G\), we have 
\[(g_1 \cdot (g_2 \cdot f))(x) = (g_2 \cdot f)(f(g_1^{-1} \cdot x)) = 
  f(g_2^{-1} g_1^{-1} \cdot x) = f((g_1 g_2)^{-1} \cdot x) = (g_1 g_2 \cdot f)(x).\]
In the case that \(X = G\), we again have the 3 representations on \(\mathbb{C}^X\),
\begin{itemize}
  \item left regular \((g \cdot_L f)(h) = f(g^{-1} h)\);
  \item right regular \((g \cdot_R f)(h) = f(hg)\);
  \item adjoint \((g \cdot_{ad} f)(h) = f(g^{-1} h g)\).
\end{itemize}
We will mainly only use the adjoint representation in this section. 

\begin{proposition}
  \(\text{Fun}_{cl}(G, \mathbb{C}) = (\mathbb{C}^X)^{G_{ad}}\), i.e. the set of 
  class functions equals to the \(G\)-invariant subspace of \(\mathbb{C}^X\) 
  with respect toe the adjoint representation.
\end{proposition}
\begin{proof}
  Unfold the definitions.
\end{proof}

By the property of the trace, it is clear that characters are class functions,
and thus, we have the chain of subsets 
\[\{\text{Characters}\} \subseteq \text{Fun}_{cl}(G, \mathbb{C}) = 
(\mathbb{C}^X)^{G_{ad}} \subseteq \mathbb{C}^X.\]
In the case that \(G\) is finite, as mentioned before, we have the isomorphism 
\((\mathbb{C}^X)^{G_{ad}} \cong \mathbb{C}[G]^{G_{ad}}\) where the dimension of 
the latter is the number of conjugacy classes. Hence the number of irreducible 
representations equal \(\dim (\mathbb{C}^X)^{G_{ad}}\). Thus, the following 
proposition is motivated.

\begin{definition}
  An irreducible character is a character of an irreducible representation.
\end{definition}

\begin{proposition}
  The irreducible characters form a basis for the set of class functions. 
  In fact, we will define an inner product on this space and show that 
  this basis is orthonormal.
\end{proposition}

This proposition immediately implies \((V, \rho_V) \not\cong (W, \rho_W)\) 
implies \(\chi_V \neq \chi_W\) since if otherwise, we have found two character 
linearly dependent with each other.

\begin{lemma}
  Let \(T \in GL(V)\) such that \(T^n = \text{id}_V\) for some \(n \ge 1\), 
  then \(T\) is diagonalisable with eigenvalues being the \(n\)-roots of unity.
\end{lemma}
\begin{proof}
  Follows by considering the minimal polynomial, in particular the primary 
  decomposition theorem.

  Alternatively using group representation theory, we note that 
  \(\langle T \rangle\) form a finite cyclic group under composition, and 
  so the representation \((V, \rho_V)\) on \(\langle T \rangle\) where 
  \(\rho_V(T) = T\) is decomposable into 1-dimensional subrepresentations. 
  Hence, \(\rho_V(T) = T\) has an eigenbasis and so is diagonalisable. 
  Finally, as \(T^n = \text{id}_V\), we have the 
  eigenvalues being the \(n\)-roots of unity.
\end{proof}

\begin{proposition}
  Let \(g \in G\) be an element of finite order and let \((V, \rho_V)\) be a 
  finite dimensional representation. Then, 
  \begin{itemize}
    \item \(\chi_V(g^{-1}) = \overline{\chi_V(g)}\);
    \item \(|\chi_V(g)| \le \dim V\) with equality if and only if 
      \(\rho_V(g) = \lambda \text{id}_V\) for some \(\lambda \in \mathbb{C}\);
    \item \(\chi_V(e) = \dim V\).
  \end{itemize}
\end{proposition}
\begin{proof}
  \(g \in G\) be an element of finite order. Then, if the eigenvalues of 
  \(\rho_V(g)\) are \(\lambda_1, \cdots, \lambda_n\), 
  \begin{itemize}
    \item if the eigenvalues of \(\rho_V(g)\) are \(\lambda_1, \cdots, \lambda_n\), 
      the eigenvalues of \(\rho_V(g^{-1})\) are 
      \(\lambda_1^{-1}, \cdots, \lambda_n^{-1}\). But, \(g^{|g|} = 1\) and so 
      \(\lambda_i^{|g|} = 1\) implying \(\lambda_i^{-1} = \overline{\lambda_i}\).
      Thus, the equality follows as the character is simply the sum of the eigenvalues. 
    \item by the triangle inequality we have 
      \[|\chi_V(g)| = |\lambda_1 + \cdots + \lambda_n| \le 
        |\lambda_1| + \cdots |\lambda_n| = 1 + \cdots + 1 = \dim V.\]
      The less equal is an equality if and only if all \(\lambda_i\) points in the 
      same direction on \(\mathbb{C}\), and since \(|\lambda_i| = 1\) for all \(i\), 
      the eigenvalues must be the same \(\lambda\). Hence 
      \(\rho_V(g) = \lambda \text{id}_V\).
    \item clear.
  \end{itemize}
\end{proof}

\begin{corollary}
  \(g \in \ker \rho_V \iff \chi_V(g) = \dim V\).
\end{corollary}

We recall that the tensor product and the direct sum interacts in a way 
similar to a semiring modulo isomorphisms. In particular, the 
dimension of a vector space is a semiring homomorphism from the space 
of vector spaces (quotiented by isomorphism) to the natural numbers, i.e. 
\[\dim : \{\text{f.d. vector spaces}\} / \cong \to \mathbb{N}.\]
Analogously, the character is a homomorphism between the representations of 
a group and the complex numbers, i.e. 
\[\chi : \{\text{representations of } G\} \to \mathbb{C}.\]

\begin{proposition}
  Let \((V, \rho_V), (W, \rho_W)\) be finite dimensional representations of 
  \(G\), then 
  \begin{itemize}
    \item \(\chi_{V \oplus W} = \chi_V + \chi_W\);
    \item \(\chi_{V \otimes W} = \chi_V \chi_W\);
    \item \(\chi_{V^*}(g) = \overline{\chi_V}(g)\);
    \item \(\chi_{\text{Hom}(V, W)}(g) = \overline{\chi_V}(g) \chi_W(g)\).
  \end{itemize}
  where the third and fourth statement requires \(g \in G\) to have finite order.
  In the case \(g\) does not have finite order, 
  \(\chi_{V^*}(g) = \chi_V(g)^{-1}\) and 
  \(\chi_{\text{Hom}(V, W)}(g) = \chi_V(g)^{-1} \chi_W(g)\) still holds.
\end{proposition}
\begin{proof}
  Clear by choosing a basis.
\end{proof}

\subsection{Orthogonality of Characters}

Recall the definition of a Hermitian inner product (in particular, we will 
assume linearity with respect to the first argument) and some elementary 
results about orthogonality. 

\begin{proposition}
  A set of orthonormal vectors is linearly independent.
\end{proposition}

\begin{definition}
  We define the following inner product 
  \(\langle \cdot, \cdot \rangle\) on \(\mathbb{C}^G\) such that, 
  \[\langle f_1, f_2 \rangle = \frac{1}{|G|} \sum_{g \in G} f_1(g) 
    \overline{f_2(g)}.\]
\end{definition}

In the case that \(G\) is infinite but has a finite measure \(\mu\) 
(c.f. Haar measure), then we may define 
\[\langle f_1, f_2 \rangle := \frac{1}{\mu(G)} \int_G f_1(g) 
  \overline{f_2(g)} \dd \mu.\]
The properties of the finite case generalizes provided that \(G\) is compact 
and the measure is invariant under translation, i.e. 
\(\mu(X) = \mu(g \cdot X)\) for all \(g \in G, X \subseteq G\) 
(c.f. Haar's theorem).

\begin{lemma}
  Let \(T \in \text{End}(U)\) be a linear projection. Then 
  \(\dim T(U) = \text{tr}(T)\).
\end{lemma}
\begin{proof}
  We have \(U = \ker T \oplus T(U)\), and furthermore, we have 
  \(T\mid_{\ker T} = 0\) and \(T\mid_{T(U)} = \text{id}\mid_{T(U)}\) and thus, 
  \(\text{tr}(T) = \text{tr}(T\mid_{\ker T}) + \text{tr}(T\mid_{T(U)}) = 
    \dim T(U)\).
\end{proof}

\begin{theorem}
  Let \((V, \rho_V)\) and \((W, \rho_W)\) be finite dimensional representations 
  of the finite group \(G\). Then, 
  \[\langle \chi_V, \chi_W \rangle = \dim \text{Hom}_G(V, W).\]
\end{theorem}
\begin{proof}
  Recall the averaging map 
  \[\text{avg} : \text{Hom}(V, W) \to \text{Hom}(V, W) : \phi \mapsto 
    \frac{1}{|G|} \sum_{g \in G} \rho_{\text{Hom}(V, W)} (g)(\phi)\]
  is a \(G\)-linear projection with the image 
  \(\text{Hom}(V, W)^G = \text{Hom}_G(V, W)\). Now, by considering 
  \[\text{tr}(\text{avg}) = \frac{1}{|G|} \sum_{g \in G} \chi_{\text{Hom}(V, W)}(g)
    = \frac{1}{|G|} \sum_{g \in G} \overline{\chi_V(g)}\chi_W(g) = 
    \langle \chi_W, \chi_V \rangle,\]
  since \(\text{Hom}(V, W) \cong V^* \otimes W\), we have 
  \[\langle \chi_V, \chi_W \rangle = \overline{\langle \chi_W, \chi_V \rangle}  
    = \overline{\text{tr}(\text{avg})} = \overline{\dim \text{Hom}_G(V, W)}.\]
  Thus, as \(\dim \text{Hom}_G(V, W) \in \mathbb{N}\), we have 
  \(\overline{\dim \text{Hom}_G(V, W)} = \dim \text{Hom}_G(V, W)\) and 
  \[\langle \chi_V, \chi_W \rangle = \dim \text{Hom}_G(V, W).\]
\end{proof}

\begin{corollary}
  If \(V, W\) are irreducible, then 
  \[\langle \chi_V, \chi_W \rangle = \begin{cases} 
    1, \ V \cong W,\\
    0, \ V \not\cong W.
  \end{cases}\]
\end{corollary}
\begin{proof}
  By Schur's lemma.
\end{proof}

\begin{corollary}
  If \(V_1, \cdots, V_m\) are irreducible and non-isomorphic representations, 
  then \(\chi_{V_1}, \cdots, \chi_{V_m}\) are orthonormal.
\end{corollary}

\begin{corollary}
  If \(V_1, \cdots, V_m\) are all non-isomorphic irreducible representations of 
  (the finite group) \(G\) up to isomorphism, their characters form an orthonormal 
  basis of \(\text{Fun}_{cl}(G, \mathbb{C})\).
\end{corollary}
\begin{proof}
  As all characters are class functions, \(\chi_{V_1}, \cdots, \chi_{V_m}\) 
  is a linearly independent set of class functions. Now, as the dimension of 
  \(\text{Fun}_{cl}(G, \mathbb{C})\) is the number of conjugacy classes of 
  \(G\) which equals the number of irreducible representations up to isomorphism, 
  \(\chi_{V_1}, \cdots, \chi_{V_m}\) is a basis of 
  \(\text{Fun}_{cl}(G, \mathbb{C})\) as required.
\end{proof}

\begin{corollary}
  \(V \cong W \iff \chi_V = \chi_W\) for \(G\) finite. 
\end{corollary}
\begin{proof}
  It suffices to prove the reverse direction. Suppose \(V \not\cong W\), and 
  WLOG. assume \(V, W\) are irreducible. Then,  
  \(\langle \chi_V, \chi_W \rangle \neq 0\) implying \(\chi_V \neq \chi_W\).
\end{proof}

The inner product also allows us to recover the multiplicities of the 
irreducible representations. In particular, if \(V = V_1^{r_1} \oplus \cdots \oplus 
V_m^{r_m}\), then 
\[\langle \chi_V, \chi_{V_i} \rangle = 
  \langle r_1\chi_{V_1} + \cdots + r_m \chi_{V_m}, \chi_{V_i} \rangle = r_i.\]

\subsection{Character Table}

We have so far found one set of orthonormal basis of \(\text{Fun}_{cl}(G, \mathbb{C})\)
which are the characters belonging to the irreducible representations. On the other 
hand, we notice that there is another orthonormal basis of the class functions 
defined such that, for each conjugacy class \(C\) of \(G\), we set
\[\delta_C : G \to \mathbb{C} : g \mapsto 
  \begin{cases}
    1, \ g \in C,\\
    0, \ g \not\in C.
  \end{cases}\]
Clearly, \(\{\delta_C\}\) is orthogonal and there are 
\(\dim \text{Fun}_{cl}(G, \mathbb{C})\) of them, and thus form a basis. Now, 
to obtain an orthonormal basis, by simply considering 
\[\langle \delta_C, \delta_C \rangle = 
  \frac{1}{|G|}\sum_{g \in G} \delta_C(g)^2
  = \frac{|C|}{|G|},\]
we see that \(\{\sqrt{|G| / |C|} \delta_C\}\) form an orthonormal basis of 
\(\text{Fun}_{cl}(G, \mathbb{C})\).

Thus, we have two sets of orthonormal basis of the class functions and we may 
ask what is the change of basis matrix between the two. In particular, we 
see that the change of basis matrix has \((i, j)\)-entry 
\(\sqrt{|C_j| / |G|}\chi_{\rho_i}(g_j)\) where \(g_j\) is any element of 
\(C_j\). Commonly however, we omit the normalization and so define 
a matrix \(A\) such that \(A_{ij} = \chi_{\rho_i}(g_j)\) and we refer to this 
as the character table.

\begin{definition}[Unitary]
  A unitary matrix \(A\) is a matrix such that \(A^{-1} = \overline{A^T}\).
\end{definition}

\begin{proposition}
  \(A\) is unitary if and only if the row of \(A\) are orthonormal if and only 
  if the column of \(A\) are orthonormal.
\end{proposition}

\begin{proposition}
  A change of basis matrix between two orthonormal bases is unitary.
\end{proposition}

By the orthogonality of the columns of the character table \(A\), we obtain 
\[\delta_{ij} = \frac{\sqrt{|C_i||C_j|}}{|G|}\sum_{k = 1}^m 
  \chi_{V_k}(g_i)\overline{\chi_{V_k}(g_j)},\]
and so, 
\[|C_i| = |G| \left(\sum_{k = 1}^m |\chi_{V_k}(g_i)|^2\right)^{-1}.\]
In the case that \(C_i = \{e\}\) the trivial conjugacy class, we see that 
this formula provides \(|G| = \sum |\chi_{V_k}(e)|^2 = \sum |\dim V_k|^2\). 

\begin{proposition}
  \(\sum \dim V_i \chi_{V_i} = |G| \delta_{e}\).
\end{proposition}
\begin{proof}
  Exercise.
\end{proof}

\subsection{Normal Subgroups, Centre and Automorphisms}

Recall that the kernel of a group homomorphism is a normals subgroup. 
In particular, as group representations are homomorphisms, a representation 
automatically provides a normal subgroup. We ask the converse where if 
we have a normal subgroup, can we construct a group representation.

\begin{proposition}
  Let \(N \trianglelefteq G\) be a normal subgroup of \(G\). Let 
  \(V = \mathbb{C}[G / N]\) be the representation attached to the action 
  \[\rho_V : G \times G / N \to G / N : g \cdot hN \mapsto (gh) N.\]
  Then \(\ker \rho_V = N\).
\end{proposition}
\begin{proof}
  \(g \in \ker \rho_V \iff ghN = hN, \ \forall h \in G \iff 
    h^{-1}gh \in N, \ \forall h \in G \iff g \in N\).
\end{proof}

So all normal subgroup are kernels of representation. 

\begin{proposition}
  \(\ker \rho_{V \oplus W} =  \ker \rho_V \cap \ker \rho_W\).
\end{proposition}
\begin{proof}
  \(g \in \ker \rho_{V \oplus W} \iff \rho_{V \oplus W}(g) = \text{id}_V \oplus 
  \text{id}_W \iff \rho_V(g) = \text{id}_V \wedge \rho_W(g) = \text{id}_W 
  \iff g \in \ker \rho_V \cap \ker \rho_W\).
\end{proof}

\begin{corollary}
  For \(|G| < \infty\), every normal subgroup is an intersection of kernels of 
  irreducible representations.
\end{corollary}
\begin{proof}
  Let \(N \trianglelefteq G\), then \(N = \ker \rho_{\mathbb{C}[G / N]}\). 
  Then, by Maschke's, we may decompose \(\rho_{\mathbb{C}[G / N]}\) into 
  irreducible subrepresentations and so, \(N\) is the intersection of the 
  kernels of these irreducible subrepresentations.
\end{proof}

Now, recall that if \(|\chi_V(g)| = \dim V\), then 
\(\rho_V(g) = \lambda \text{id}_V\) we have \(\chi_V(g) = \dim V\) 
if and only if \(\rho_V(g) = \text{id}\). Thus,
\(\ker \rho_V = \{g \in G \mid \chi_V(g) = \dim V\}\).
With this we may classify the normal subgroups of a finite group by 
constructing the character table and see when \(\chi_V(g) = \dim V\).

Consider \(z \in Z(G)\) (where we denote \(Z(G)\) for the centre of 
\(G\), then \(\rho_V(z) : V \to V\) is a \(G\)-linear map since 
for all \(g \in G\), \(\rho_V(z) \circ \rho_V(g) = \rho_V(zg) = \rho_V(gz) = 
\rho_V(g) \circ \rho_V(z)\). Thus, if \(V\) is irreducible, by Schur's lemma, 
\(\rho_V(z) = \lambda\text{id}_V\) for some \(\lambda \in \mathbb{C}\).
Furthermore, we have \(|\chi_V(z)| = \dim V\). The converse turns out to be 
also true.

\begin{proposition}
  If \(G\) is finite and \(|\chi_V(z)| = \dim V\) for all irreducible 
  representations \((V, \rho_V)\), then \(z \in Z(G)\). 
\end{proposition}
\begin{proof}
  If \(|\chi_V(z)| = \dim V\), then \(\rho_V(z) = \lambda\text{id}_V\). Then, 
  for all \(g \in G\), \(\rho_V(z)\rho_V(g) = \lambda\rho_V(g) = 
  \rho_V(g)\rho_V(z)\). Thus, by Maschke's, \(\rho_V(zg) = \rho_V(z)\rho_V(g) = 
  \rho_V(g)\rho_V(z) = \rho_V(gz)\) for all finite dimensional representations 
  of \(G\). Then, it suffices to find a faithful finite dimensional representation. 
  In particular, the regular representation are faithful, and so 
  \(z g = g z\) for all \(g \in G\) and hence, \(z \in Z(G)\).
\end{proof}

\begin{proposition}
  The commutator subgroup is the intersection of the kernels of 
  the 1-dimensional representations, i.e.
  \[[G, G] = \bigcap_{\dim V = 1} \ker \rho_V.\]
\end{proposition}
\begin{proof}
  Recall that the 1-dimensional representations of \(G\) correspond to the 
  1-dimensional representations of \(G_{ab}\), so \([G, G] \le \ker \rho_V\)
  for \(\dim V = 1\). Conversely, by considering that the intersection of 
  all \(\ker \rho_V\) for \((V, \rho_V)\) 1-dimensional representations of 
  \(G_{ab}\) must be the intersection of all normal subgroups of \(G_{ab}\), 
  this intersection must be \(\{e\}\).
\end{proof}

Recall that if we have a group homomorphism \(\phi : G \to H\), then a 
representation \((V, \rho_V)\) of \(H\) can be pulled back along \(\phi\) to 
a representation of \(G\) with \((V, \rho_V \circ \phi)\). One can show that 
if \(\phi\) is surjective, then \((V, \rho_V)\) is irreducible if and only 
if \((V, \rho_V \circ \phi)\) is irreducible. So for \(\phi\) surjective, 
this embeds a character table of \(H\) inside that of \(G\).

Now, if \(\phi : G \simeq H\) is an isomorphism, the character tables 
of \(G\) and \(H\) are identical up to reordering of rows and columns.
In particular, an automorphism provides a symmetry for the character table 
in which \(\chi(g) = (\chi \circ \phi^{-1})(\phi(g))\).

\newpage
\section{Algebras and Modules}

So far we have looked at representations of groups and in most cases, finite 
groups. We will now turn our attention to something more general but before 
doing this, we will motivative this generalization with infinite groups.

Previously, we have seen that the characters of irreducible representations 
form an orthonormal basis of the class functions for finite groups. In the 
case of infinite groups this is no longer the case as we no longer have 
an inner product (provided we are not dealing with Haar measures). Nonetheless, 
we may still say something about their characters.

\begin{proposition}
  If \((V_1, \rho_{V_1}), \cdots, (V_m, \rho_{V_m})\) are finite dimensional 
  non-isomorphic irreducible representations of \(G\), then the their characters 
  \(\chi_{V_1}, \cdots, \chi_{V_m}\) are linearly independent.
\end{proposition}
\begin{proof}
  Follows from proposition \ref{spans}.
\end{proof}

Also, we no longer require \(\mathbb{C}\) or an algebraically closed field 
since we will not be using Maschke's theorem. Nonetheless, we still require 
finite dimensional as otherwise we cannot even define the trace.

\begin{lemma}
  Let \((V, \rho)\) be a finite dimensional representation of \(G\). Then, 
  if \(\rho(G)\) spans \(\text{End}(V)\), then \((V, \rho)\) is irreducible.
\end{lemma}
\begin{proof}
  Suppose \(W \subseteq V\) is a non-trivial subrepresentation and 
  let \(w \in W \setminus \{0\}\). Then, for all \(v \in V\), take 
  \(T \in \text{End}(V)\), such that \(T(w) = v\). As \(\rho(G)\) spans 
  \(\text{End}(V)\), there exists a representation of \(T\) so that, 
  \[T = a_1 \rho_(g_1) + \cdots + a_m \rho(g_m).\]
  Thus, \(v = Tw = a_1 \rho(g_1)(w) + \cdots + a_m \rho(g_m)(w)\). But now, 
  as \(W\) is a subrepresentation of \(V\), \(\rho(g_i)(w) \in W\) for all \(i\), 
  and hence, by linearity, 
  \(v = a_1 \rho(g_1)(w) + \cdots + a_m \rho(g_m)(w) \in W\) implying \(W = V\).
\end{proof}

The converse of the this lemma is also true. 

\begin{proposition}\label{spans}
  Let \((V, \rho)\) be a irreducible finite dimensional representation, then 
  \(\rho(G)\) spans \(\text{End}(V)\). Furthermore, if \((V_1, \rho_{V_1}), 
  \cdots, (V_m, \rho_{V_m})\) are finite dimensional non-isomorphic 
  irreducible representations, then \(\{(\rho_1(g), \cdots, \rho_m(g)) \mid g \in G\}\) 
  spans \(\text{End}(V_1) \oplus \cdots \oplus \text{End}(V_m)\).
\end{proposition}

To understand and to prove these statements will require a more general theory, 
hence our study of algebras and modules.

\subsection{Definitions}

\begin{definition}[\(\mathbb{C}\)-algebra]
  The group algebra of a group \(G\) is the free vector space \(\mathbb{C}[G]\) 
  equipped with the multiplication 
  \[\left(\sum a_g g\right) \left(\sum b_h h\right) = \sum_{g, h} a_g b_h gh,\]
  where all but finitely many terms are zero.
\end{definition}

We observe that a representation can extend linearly to the group algebra. 
In particular, if \((V, \rho)\) is a representation of \(G\), then we may define
\[\tilde \rho\left(\sum a_g g\right) := \sum a_g \rho(g) \in \text{End}(V).\]
Recall that \(\text{End}(V)\) is a noncommutative ring with the multiplication 
\(\phi \psi := \phi \circ \psi\) and we see that \(\tilde \rho\) is a 
\(\mathbb{C}\)-linear ring homomorphism. Furthermore, we have 
\(\tilde \rho \mid_G = \rho\). Thus, we have a bijection between the set of 
representations of \(G\) on \(V\) and the set of \(\mathbb{C}\)-linear ring 
homomorphisms from \(\mathbb{C}[G]\) to \(\text{End}(V)\).

\begin{definition}[Algebra]
  An algebra \(A\) on a field \(F\) is a (not necessary commutative) ring which 
  is also an \(F\)-vector space satisfying 
  \[c \cdot (ab) = (c \cdot a)b = a(c \cdot b),\]
  for all \(c \in F\), \(a, b \in A\).
\end{definition}

Equivalently, one may define an algebra to be a ring \(A\) equipped with a 
injective ring homomorphism \(F \hookrightarrow Z(A)\) where \(F\) is a field and 
\(Z(A) := \{z \in A \mid \forall a \in A, \ az = za\}\), i.e. 
the \(A\) contains \(F\) in its centre. 

\begin{definition}[Algebra Homomorphism]
  Given \(A, B\) \(F\)-algebras, a \(F\)-algebra homomorphism is a map 
  \(\phi : A \to B\) that is a ring homomorphism and \(F\)-linear.
\end{definition}

If \(A\) is an \(\mathbb{F}\)-algebra, then there is always an algebra 
homomorphism \(F \to A\) given by \(\lambda \mapsto \lambda \cdot 1_A\).

\begin{definition}[Module]
  A module over an \(F\)-algebra \(A\) is a pair \((V, \rho)\) where 
  \(V\) is a \(F\)-vector space and \(\rho : A \to \text{End}(V)\) in an algebra 
  homomorphism.
\end{definition}

As demonstrated above, if \((V, \rho)\) is a representation, then \((V, \tilde \rho)\) 
is a module over \(\mathbb{C}[G]\).

If \(V\) is a \(F\)-vector space, it is easy to see that \(A := \text{End}(V)\) is 
an \(F\)-algebra, and furthermore, \(A\) is an module over itself by taking 
\(\rho := \text{id}_A\).

Another famous example is known as the Gelfand-Naimark duality. If 
\(X\) is a compact Hausdorff topological space, then there is an theorem stating 
that we have an equivalence between \(X\) and its algebra of continuous 
functions \(C(X)\). In particular, given a continuous function \(\phi : X \to Y\), we 
have its pull-back \(\phi^* : C(Y) \to C(X) : f \mapsto f \circ \phi\) in 
the commutative \(C^*\)-algebras (see the functional analysis course).

Similarly, in algebraic geometry, we study the duality between the varieties, 
i.e. 
\[X = \{f_1(x_1, \cdots, x_n) = \cdots = f_m(x_1, \cdots, x_n) = 0 \mid 
  f_1, \cdots, f_m \in \mathbb{C}[x_1, \cdots, x_n]\} 
  \subseteq \mathbb{C}^n\]
and algebras \(\mathcal{O}(X) := \mathbb{C}[x_1, \cdots, x_n] / (f_1, \cdots, f_m)\).

\begin{definition}[Submodule]
  A submodule of a module \((V, \rho_V)\) over \(A\) is a subspace \(W \le V\) such 
  that, \(\rho_V(a)(W) \subseteq W\) for all \(a \in A\).
\end{definition}

\begin{definition}[Module Homomorphism]
  A module homomorphism between to modules \((V, \rho_V)\) and \((W, \rho_W)\) is 
  a linear map \(T : V \to W\) such that \(T \circ \rho_V(a) = \rho_W(a) \circ T\) 
  for all \(a \in A\). We denote \(\text{Hom}_A(V, W)\) for the set of 
  module homomorphisms between \((V, \rho_V)\) and \((W, \rho_W)\).
\end{definition}

\begin{definition}[Decomposable]
  A module \((V, \rho_V)\) is decomposable if there exists proper submodules 
  \(W_1, W_2\) such that \(V = W_1 \oplus W_2\). We say a module is indecomposable 
  if it is not decomposable unless \(V = 0\). 
\end{definition}

\begin{definition}[Reducible]
  A module \((V, \rho_V)\) is reducible if there exists a non-trivial, proper 
  submodule \(W\). If \((V, \rho_V)\) is not reducible, then we say it is 
  simple (or irreducible) unless \(V = 0\).
\end{definition}

\begin{definition}[Semisimple]
  A module \((V, \rho_V)\) is semisimple if there exists simple submodules 
  \(W_1, \cdots, W_m\) such that \(V = W_1 \oplus \cdots \oplus W_m\). 
\end{definition}

We see that these definition are essentially the same as the ones for 
representations. Indeed, as justified earlier, a module is simply  
representations of algebras.

\begin{definition}[Regular Module]
  Let \(A\) be an algebra, then the regular module over \(A\) is \(A\) over 
  itself equipped with the algebra homomorphism 
  \[\rho : A \mapsto \text{End}(A) : a \mapsto a (\cdot).\]
\end{definition}

We will continue to work with \(\mathbb{C}\) though all following statements also 
work for any algebraically closed field.

\begin{lemma}[Schur's Lemma]
  If \(T : V \to W\) is a module homomorphism and \(V\) is simple, then 
  \(T\) is either 0 or an faithful (in the case that 
  \(W\) is also simple, then \(T\) is an isomorphism). Furthermore, if 
  \(V\) is simple and finite dimensional, then 
  \(\text{End}_A(V) = \mathbb{C} \cdot \text{id}_V\).
\end{lemma}
\begin{proof}
  Same proof as the representation case.
\end{proof}

\begin{proposition}
  If \((V, \rho_V)\) is an \(A\)-module and \(\rho_V : A \to \text{End}(V)\) is 
  surjective, then \((V, \rho_V)\) is simple. Furthermore, if \(V\) is 
  finite dimensional, then the converse holds.
\end{proposition}

While similar to the representation case, we may define the external direct sum of 
two modules, unlike the representation case, we may not define the tensor product 
as the scalar multiplication operation is linear, not bilinear. Indeed, if we 
have something called a bi-algebra, then it is possible to define the tensor 
product.

\subsection{Semisimplicity and Matrix Algebras}

We recall that finite dimensional representations of \(G\) over \(\mathbb{C}\) 
are semi simple. Thus, by the bijective correspondence, the same is true 
for finite dimensional modules over the group algebra \(\mathbb{C}[G]\).
Also recall that we have the isomorphism 
\(\mathbb{C}[G] \to \bigoplus \text{End}(V_i)\) if \((V_1, \rho_{V_i}), \cdots, 
(V_m, \rho_{V_m})\) are irreducible up to isomorphism, and in fact, we 
now see this is also a algebra homomorphism.

\begin{definition}[Semisimple Algebra]
  For \(\dim_F A < \infty\), \(A\) is said to be semisimple if 
  every finite dimensional \(A\)-module is semisimple.
\end{definition}

\begin{lemma}
  If \((V, \rho_V)\) is an \(A\)-module, and \(v \in V \setminus \{0\}\), we 
  define \(\phi_v : A \to V : a \mapsto \rho_V(a)(v)\). Then \(\phi_v\) is a 
  surjective \(A\)-module homomorphism if \(V\) is simple.
\end{lemma}
\begin{proof}
  \(\phi_V(A) \subseteq V\) is a submodule and so, \(\phi_V(A) = \{0\}\) or 
  \(\phi_V(A) = V\). This first case is impossible since \(\phi_V(e) = 
  \rho_V(e)(v) = v \neq 0\).
\end{proof}

With this in mind, we see that we can find all simple modules from \(A\) by 
considering \(V \cong A / \ker \phi_v\) by the first isomorphism theorem.

\begin{proposition}
  If the regular \(A\)-module only contains the unique simple submodule \(V\), then 
  every simple \(A\)-module is isomorphic to \(V\).
\end{proposition}
\begin{proof}
  If \((W, \rho_W)\) is simple and \(w \in W \setminus \{0\}\), then 
  we have \(W \cong A / \ker \phi_w\). It is clear that \(\ker \phi_w \neq \{0\}\) 
  and \(\ker \phi_w \neq A\) and so, \(\ker \phi_w = V\). Applying 
  \(W = V\), we obtain \(V \cong A / V\) and so \(W \cong A / V \cong V\).
\end{proof}

\begin{proposition}
  If \(V = V_1 \oplus \cdots \oplus V_m\) where \(V_i\) is simple for all \(i\), 
  then every submodule \(U \subseteq V\) has a complementary submodule of the 
  form 
  \[V_I = \bigoplus_{i \in I}, \text{ for some } I \subseteq \{1, \cdots, m\}.\]
\end{proposition}
\begin{proof}
  Let \(I \subseteq \{1, \cdots, m\}\) be maximal such that \(U \cap V_I = \{0\}\). 
  Then \(V = U \bigcup V_I\) since if otherwise, for some \(i \in I\), 
  \(V_i \not\subseteq U \oplus V_I\). But, as \(V_i\) is simple, we have
  \(V_i \cap U \oplus V_I = \{0\}\) and so \(U \cap (V_i \oplus V_I)\) contradicting 
  the maximality of \(I\).
\end{proof}

\begin{corollary}
  Every submodule and quotient module of a semisimple module is semisimple.
\end{corollary}
\begin{proof}
  Let \(U \subseteq V = \bigcup_i V_i\) be a submodule and suppose it has complement 
  \(V_I\). Then \(V / U \cong U \oplus V_i / U \cong V_I\) which is semisimple.

  Similarly, the composition of the inclusion map \(\iota : U \to V\) and the 
  quotient map \(q : V \to V / V_I\) is an isomorphism implying \(U\) is semisimple.
\end{proof}

\begin{lemma}
  Let \(V\) be an \(n\)-dimensional module over \(A\), then \(V\) is isomorphic 
  to a quotient module of \(A^n\).
\end{lemma}
\begin{proof}
  Let \(\{v_1, \cdots, v_n\}\) be a basis of \(V\) and define the surjection 
  \[\phi : (a_1, \cdots, a_n) \mapsto a_1 v_1 + \cdots a_n v_n = 
    \rho(a_1)(v_1) + \cdots + \rho(a_n)(v_n).\]
  Then \(V \cong A^n / \ker \phi\) as required.
\end{proof}

\begin{proposition}
  \(A\) is semisimple if and only if \(A\) is semisimple as a 
  (left regular) module over itself.
\end{proposition}
\begin{proof}
  The forward direction is clear so let us consider the reverse. 

  Suppose \(A\) is a semisimple \(A\)-module and let \(V\) be a finite-dimensional 
  \(A\)-module. Then, by the above lemma, \(V\) is isomorphic to 
  some quotient module of \(A^n\) and so, it suffices to show \(A^n\) is 
  semisimple. But this is clear since \(A^n = A \oplus \cdots \oplus A\) and 
  the direct sum of semisimple modules is semisimple.
\end{proof}

\begin{definition}[Opposite Algebra]
  Given an algebra \(A\), the opposite algebra \(A^{op}\) is the algebra 
  \(A\) with the reversed multiplication, i.e. \(a \cdot_{op} b = ba\).
\end{definition}

We note that the same construction can be made for groups but \(G \simeq G^{op}\) 
by the map \(g \mapsto g^{-1}\).

\begin{lemma}
  The map \(\text{End}_A A \to A^{op} : \phi \mapsto \phi(1_A)\) is an algebra 
  isomorphism.
\end{lemma}
\begin{proof}
  The inverse is \(a \mapsto \phi_a\) where \(\phi_a(b) := ba\).
\end{proof}

\begin{theorem}[Artin-Wedderburn]
  Given a finite dimensional algebra \(A\), the following are equivalent:
  \begin{enumerate}
    \item every finite dimensional \(A\)-module is semisimple, i.e. 
      \(A\) is semisimple;
    \item \(A\) is isomorphic to a direct sum of matrix algebras, i.e.
      \(A \cong \bigoplus_{i = 1}^m \text{Mat}_{n_i}(\mathbb{C})\);
    \item there is a full set of simple left \(A\)-modules \(V_1, \cdots, V_m\) 
      and an isomorphism \(A \cong \bigoplus_{i = 1}^m \text{End}(V_i)\).
  \end{enumerate}
\end{theorem}

We see that both the second and third statement implies the sum of squares formula.

\begin{proof}
  It is clear that 2 and 3 are equivalent by simply picking basis. 
  
  We will now show 2 implies 1. 
  Recall that \(A\) is semisimple if and only if \(A\) is semisimple as a 
  (left regular) \(A\)-module over itself and since 
  \(A \cong \bigoplus \text{Mat}_{n_i}(\mathbb{C})\), it suffices to show 
  \(\bigoplus \text{Mat}_{n_i}(\mathbb{C})\) is semisimple over itself. 
  Recalling that \(\mathbb{C}^{n_i}\) is semisimple 
  as a \( \text{End}(\mathbb{C}^{n_i})\)-module and
  and \(\text{Mat}_{n_i}(\mathbb{C}) \cong \mathbb{C}^{n_i} \oplus \cdots \oplus 
  \mathbb{C^{n_i}}\), we have \(\text{Mat}_{n_i}(\mathbb{C})\) is a semisimple 
  \(\bigoplus_i \text{Mat}_{n_i}(\mathbb{C})\) implying the result.

  Finally, we will show 1 implies 2. Suppose \(A\) is semisimple and let 
  write \(A = V_1^{r_1} \oplus \cdots V_n^{r_n}\) where \(V_i\) are 
  pair-wise nonisomorphic. As we have shown above, \(\text{End}_A A \cong A^{op}\)
  and so, 
  \[A^{op} \cong \text{End}_A(V_1^{r_1} \oplus \cdots \oplus V_n^{r_n})
   \cong \text{Mat}_{r_1}(\mathbb{C}) \oplus \cdots \oplus 
   \text{Mat}_{r_n}(\mathbb{C}).\]
  On the other hand, \(\text{Hom}(V_i^{r_i}) \cong \text{Mat}_{r_i}(\mathbb{C})\) 
  by Schur's lemma, and thus we have 1 implies 2. 
\end{proof}

\subsection{Character Theory and Abstract Traces}

We again visit character theory in the point of view of modules and we will 
show that, in general algebras, the map \(A \to \text{End}(V)\) is surjective 
(Artin-Wedderburn tells us that if \(A\) is finite dimensional and semisimple 
then the map is an isomorphism).

\begin{proposition}
  Let \(A\) be an algebra and \(V_1, \cdots, V_m\) be non-isomorphic simple 
  finite-dimensional \(A\)-modules, then the map
  \[\bigoplus_{i = 1}^m \rho_{V_i} : A \to \bigoplus_{i = 1}^m \text{End}(V_i)\] 
  is surjective.
\end{proposition}
\begin{proof}
  Let \(B = \bigoplus_i \rho_{V_i}(A) \subseteq \bigoplus_i \text{End}(V_i)\), 
  then \(B\) is an \(A\)-module under left multiplication, i.e.
  \[\rho_V(a)(b) = (\rho_{V_1}(a), \cdots, \rho_{V_m}(a))b.\]
  Then, since \(V_i\) is semisimple, \(\text{End}(V_i) \cong V_i^{\dim V_i}\) 
  and so, \(B\) is semisimple. Thus, as \(B\) is finite dimensional, it 
  is a semisimple algebra. Now, by observing that \(V_i\) are simple, non-isomorphic 
  \(B\)-modules, by Artin-Wedderburn, for \(V_1, \cdots V_m, W_1, \cdots, W_n\)
  all simple \(B\)-modules, we have 
  \[B \cong \bigoplus \text{End}(V_i) \oplus \bigoplus \text{End}(W_i).\]
  But \(B \subseteq \bigoplus \text{End}(V_i)\), and so, by dimensional 
  argument, we have \(B = \bigoplus \text{End}(V_i)\) and hence, the map is 
  surjective.
\end{proof}

\begin{definition}[Character]
  Given a finite dimensional \(A\)-module \((V, \rho_V)\), we define its 
  character to be 
  \[\chi_{\rho_V}(a) := \text{tr}(\rho_V(a)).\]
\end{definition}

\begin{proposition}
  Given \(\{V_i\}\) non-isomorphic simple finite-dimensional \(A\)-modules,
  \(\{\chi_{V_i}\}\) are linearly independent.
\end{proposition}
\begin{proof}
  Suppose \(\lambda_1 \chi_{V_1} + \cdots + \lambda_m \chi_{V_m} = 0\). Then, 
  by the above proposition, \(A \to \bigoplus \text{End}(V_i)\) is surjective and 
  so, for all \(j\), there exists some \(a \in A\) such that 
  \(\text{tr}(\rho_{V_j}(a)) = 1\) and \(\rho_{V_i}(a) = 0\) for all \(i \neq j\).
  Then, 
  \[0 = \lambda_1 \chi_{V_1}(a) + \cdots + \lambda_m \chi_{V_m}(a) = \lambda_j\]
  for each \(j\). Hence \(\{\chi_{V_i}\}\) are linearly independent.
\end{proof}

\begin{corollary}
  Let \(G\) be a (not necessary finite) group and \(V_1, \cdots, V_m\) be 
  non-isomorphic, finite dimensional, irreducible representations of \(G\). Then, 
  \(\chi_{V_1}, \cdots, \chi_{V_m}\) are linearly independent.
\end{corollary}

Recall that given an irreducible, finite dimensional representation 
\((V, \rho_V)\), the character \(\chi_V\) is a class function by the property 
of the trace. We would like to generalize this notion for algebras.
In particular, we note that the character satisfy 
\[\chi_{\rho_V}(ab) = \text{tr}\rho_V(ab) = \text{tr}(\rho_V(a)\rho_V(b)) = 
  \text{tr}(\rho_V(b)\rho_V(a)) = \chi_{\rho_V}(ba).\]

\begin{definition}
  An abstract (or Hochschild) trace is a functional 
  \[\phi : A \to \mathbb{C}\]
  such that \(\phi(ab) = \phi(ba)\) for all \(a, b \in A\).
\end{definition}

Equivalently, we \(\phi(ab - ba) = 0\) for all \(a, b \in A\) which implies 
\([A, A] \le \ker \phi\) where \([A, A] = \text{span}\{ab - ba \mid a, b \in A\}\).
\([A, A]\) is known as the additive commutator and is analogues to the 
group commutator. Thus, by the universal property of the quotient, 
an abstract trace is uniquely identified by the map 
\(\tilde \phi : A / [A, A] \to \mathbb{C}\) where \(A / [A, A] \cong HH_0(A)\) 
where \(HH_0(A)\) is known as the zeroth Hoschild homology.

We note that in the group case, where we defined the class function to be 
functions \(\phi : G \to \mathbb{C}\) which satisfy \(\phi(hgh^{-1}) = \phi(g)\), 
an abstract trace is the same as a class function.

\begin{definition}
  With the above remark in mind, we have 
  \[\{\text{abstract traces}\} \cong \left(\frac{A}{[A, A]}\right)^*\]
  where \(*\) denotes the dual, and so, we define \(A_{\text{tr}}^* \subseteq A^*\) 
  the space of abstract traces. 
\end{definition}

It is clear that characters are abstract traces. 

Recall that in the group case, by Mascke's theorem, if \(W \le V\) is a 
subrepresentation, then we have \(\chi_V = \chi_W + \chi_{W^\perp}\) where 
\(W^\perp\) is the complement of \(W\). We cannot do this in general for 
algebras though we may do something similar.

Given a submodule \(W \le V\), we can always take its quotient \(V / W\). 

\begin{proposition}
  For \(W \le V\) a submodule where \(V\) is a finite dimensional module,
  we have 
  \[\chi_V = \chi_W + \chi_{V / W}.\]
\end{proposition}
\begin{proof}
  Let \(B\) be a basis of \(W\) and extend \(B \cup C\) to a basis of \(V\). 
  Then 
  \[[\rho_V(a)]_{B \cup C} = \begin{pmatrix}
    [\rho_W(a)]_{B} & \star\\
    0 & [\rho_{V / W}(a)]_{C + V}
  \end{pmatrix}.\]
  Thus, \(\chi_V = \chi_W + \chi_{V / W}\) as required.
\end{proof}

We note that in this case where the module is non-semisimple (i.e. it contains 
a submodule without being decomposable) the character no longer uniquely 
characterizes the module. Indeed, for \(V\) non-semisimple and \(W \le V\) a 
submodule,
\[\chi_V = \chi_W + \chi_{V / W} = \chi_{W \oplus V / W},\]
yet \(V \not\cong W \oplus V / W\).

\begin{corollary}
  If \((V, \rho_V)\) is \textit{any} finite dimensional module of \(A\), 
  then \(\chi_V\) is a sum of irreducible characters (characters of simple 
  module).
\end{corollary}

\begin{corollary}
  The irreducible character form a basis for the span of all characters 
  of finite dimensional modules. In particular, the span of all characters 
  is a subspace of \(A^*_{\text{tr}}\) though it might not be the whole space.
\end{corollary}

If \(A\) is commutative, then \([A, A] = 0\) and so, \(A \cong A^* = A^*_{\text{tr}}\).
In this case, the irreducible characters form a basis for \(A^*_{\text{tr}}\) 
if and only if \(\dim A\) equals to number of 1-dimensional modules (modulo 
isomorphisms) (since 1-dimensional modules are simple and hence, their characters 
are linearly independent). In this case, the surjection 
\[A \to \bigoplus_{V_i \text{ simple}} \text{End}(V_i)\]
is a isomorphism. Now, since for 1-dimensional module \(V_i\), 
\(\text{End}(V_i) \cong \mathbb{C}\), we have 
\(A \cong \mbox{C}^{\dim A}\).

\begin{proposition}
  For \(A\) a finite dimensional, semisimple algebra, the irreducible characters 
  form a basis for \(A^*_{\text{tr}}\). More generally, we have 
  \begin{itemize}
    \item \(\dim A^*_{\text{tr}} \ge \# \text{ simple modules}\);
    \item \(\dim A \ge \sum_{V_i \text{ simple}}(\dim V_i)^2\).
  \end{itemize}
  Finally, a finite dimensional \(A\) is semisimple if and only if 
  \(\dim A = \sum_{V_i \text{ simple}}(\dim V_i)^2\).
\end{proposition}
\begin{proof}
  We already know \(\dim A^*_{\text{tr}} \ge \# \text{ simple modules}\) and 
  the surjection \(A \to \bigoplus \text{End}(V_i)\) implies 
  \(\dim A \ge \sum_{V_i \text{ simple}}(\dim V_i)^2\). Furthermore, 
  we have \(\dim A = \sum_{V_i \text{ simple}}(\dim V_i)^2\), then the map 
  \(A \to \bigoplus \text{End}(V_i)\) is an isomorphism which occures if 
  and only if \(A\) is semisimple by Artin-Wedderburn.

  Now, suppose \(A\) is finite dimensional and semisimple, I claim that 
  \[[\text{End}(V_i), \text{End}(V_i)] = \{T \in \text{End}(V_i) \mid \text{tr}(T) = 0\},\]
  for all simple \(V_i\). This follows by choosing a basis and considering 
  the elementary matrices \(E_{ij} = (\delta_{ij})_{ij}\) where we have 
  \([E_{ij}, E_{kl}] = \delta_{jk}E_{il} - \delta_{il}E_{kj}\). Hence, 
  any diagonal entries is eliminated implying the trace is zero.
  Thus, \(\text{End}(V_i)^*_{\text{tr}} = \mathbb{C} \cdot \text{tr}\) implying 
  \[A^*_{\text{tr}} \cong \left(\bigoplus \text{End}(V_i)\right)^*_{\text{tr}} = 
    \bigoplus \mathbb{C} \cdot \text{tr}_{V_i},\]
  where \(\text{tr}_{V_i} = \chi_{V_i}\) implying the character forms a 
  basis of \(A^*_{\text{tr}}\).
\end{proof}

\subsection{Centre and Projections}

\begin{definition}[Centre of an Algebra]
  Given an algebra \(A\), we define its centre to be 
  \[Z(A) := \{z \in A \mid za = az, \ \forall a \in A\}.\]
  Alternatively, we may define the map \(\text{ad} : A \to \text{End}_{\mathbb{C}}(A) : a 
  \mapsto \text{ad}(a)\) where \(\text{ad}(a) : b \mapsto [a, b]\) and then, 
  \(Z(A) = \ker \text{ad}\).
\end{definition}

We observe that if \(z \in Z(A)\) and \(V\) is a finite dimensional, simple module, 
then Schur's lemma implies \(\rho_V(z) = \lambda \cdot \text{id}_V\) for 
some \(\lambda \in \mathbb{C}\) (as \(\rho_V(z)\) is \(A\)-linear).

\begin{proposition}
  \(Z(\text{End}(V)) = \mathbb{C} \cdot \text{id}_V\).
\end{proposition}
\begin{proof}
  This follows by taking a basis and observing that the matrices which commutes 
  with all other matrices are multiples of the identity matrix. 

  Alternatively, we may prove this using representation theory. Recall that 
  \(V\) is a simple module over \(\text{End}(V)\) with 
  \(\rho_V = \text{id}_{\text{End}(V)}\). Then, for all \(z \in Z(V)\), 
  by Schur's lemma, \(\rho_V(z) = \lambda \cdot \text{id}_V\) for some 
  \(\lambda \in \mathbb{C}\). But \(\rho_V(z) = z\) as \(\rho_V\) is the 
  identity, and thus, \(z = \lambda \cdot \text{id}_V\) and hence, 
  \(Z(\text{End}(V)) = \mathbb{C} \cdot \text{id}_V\).
\end{proof}

\begin{proposition}
  If \(\phi : A \to B\) is an isomorphism of algebras, then the restriction of 
  \(\phi\) onto its centre \(\phi\mid_{Z(A)} : Z(A) \to Z(B)\) is also an 
  isomorphism.
\end{proposition}

\begin{corollary}
  The isomorphism \(\Phi : \mathbb{C}[G] \cong \bigoplus_{i = 1}^m \text{End}(V_i)\) 
  restricts to an isomorphism 
  \[\Phi\mid_{Z(\mathbb{C}[G])} : Z(\mathbb{C}[G]) \cong \bigoplus_{i = 1}^m 
    \mathbb{C} \cdot \text{id}_{V_i}.\]
\end{corollary}

\begin{proposition}
  Let \(G\) be a group and let \(\mathcal{C}_1, \cdots, \mathcal{C}_m\) be the 
  conjugacy classes of \(G\), then denoting 
  \[c_i := \sum_{g \in \mathcal{C}_i} g \in \mathbb{C}[G],\]
  \(c_1, \cdots, c_m\) form a basis of \(Z(\mathbb{C}[G])\)
  and thus, \(\dim Z(\mathbb{C}[G]) = m\).
\end{proposition}
\begin{proof}
  Linear independence follows since \(\mathcal{C}_i \cap \mathcal{C}_j = 
  \varnothing\), and so it suffice to show spanning. Consider for all 
  \(x = \sum_{g \in G} x_g g \in \mathbb{C}[G]\), I claim that 
  \(x \in Z(\mathbb{C}[G])\) if and only if \(x_g = x_{hgh^{-1}}\) for all 
  \(h \in G\). Indeed, if \(x \in Z(\mathbb{C}[G])\), then 
  \[x = h^{-1}xh = \sum_{g \in G} x_g h^{-1}gh = 
    \sum_{hgh^{-1} \in G} x_{hgh^{-1}} g = \sum_{g \in G} x_{hgh^{-1}} g.\]
  Thus, \(x_g = x_{hgh^{-1}}\) for all \(h \in G\). On the other hand, if 
  \(x_g = x_{hgh^{-1}}\) for all \(h \in G\), then for all 
  \(y = \sum_{g \in G} y_g g \in \mathbb{C}[G]\), we have 
  \[\begin{split}
    xy & = \sum_{g, h \in G} (x_g y_h) \cdot gh = 
    \sum_{hgh^{-1}, h \in G} (x_{hgh^{-1} y_h}) \cdot (hgh^{-1})h\\ 
    & = \sum_{hgh^{-1}, h \in G} (x_g y_h) \cdot g h = 
    \sum_{g, h \in G}(x_g y_h) \cdot g h = yx
  \end{split}\]
  implying \(x \in Z(\mathbb{C}[G])\) as required. Hence, it follows 
  \(c_1, \cdots, c_m\) spans \(Z(\mathbb{C}[G])\).
\end{proof}

\begin{corollary}
  Since \(Z(\mathbb{C}[G]) \cong \bigoplus_{i = 1}^m 
  \mathbb{C} \cdot \text{id}_{V_i}\), taking the dimension on both sides, 
  we again obtain that the number of conjugacy classes equals the number of 
  irreducible representations.
\end{corollary}

In summary, we have the following three equivalent statements:
\begin{itemize}
  \item \(a \in \mathbb{C}[G]\) is central,
  \item \(a = \sum a_g g \in \mathbb{C}[G]\) where \(a_g = a_{hgh^{-1}}\) 
    for all \(g, h \in G\),
  \item for all irreducible representations \((V, \rho_V)\), 
    \(\rho_V(a) = \lambda_a \cdot \text{id}_V\) for some \(\lambda_a \in \mathbb{C}\).
\end{itemize}

\begin{proposition}
  If \(A\) is a finite dimensional, semisimple algebra, then we have the isomorphism 
  \[A^*_{\text{tr}} \to Z(A)^* : \phi \mapsto \phi\mid_{Z(A)}.\]
\end{proposition}
\begin{proof}
  By Artin-Wedderburn, it suffices to show the statement for 
  \(A = \text{Mat}_n(\mathbb{C})\). Recall that 
  \((\text{Mat}_n(\mathbb{C}))^*_\text{tr} = \mathbb{C} \cdot \text{tr}\) and 
  \(Z(\text{Mat}_n(\mathbb{C}))^* = (\mathbb{C} \cdot I_n)^*\) and so, 
  the map becomes 
  \[\lambda \cdot \text{tr} \mapsto (\mu I \mapsto n\lambda \mu),\]
  since \(\text{tr}(\mu I) = n\mu\). This is clearly an isomorphism of 
  1-dimensional vector spaces and so we have the required isomorphism.
\end{proof}

Now that we have established the isomorphism 
\(Z(\mathbb{C}[G]) \cong \bigoplus_{i = 1}^m 
\mathbb{C} \cdot \text{id}_{V_i}\), we would like to ask the preimage of 
\(\text{id}_{V_i}\) along this isomorphism. By definition, let us write 
\(\rho_{V_i}(z) = \lambda_{z, i} \cdot \text{id}_{V_i}\) for all 
\(z \in Z(\mathbb{C}[G])\). Then, we have \(\chi_{V_i}(z) = \lambda_{z, i} \dim V_i\), 
and so, 
\[\lambda_{z, i} = \frac{1}{\dim V_i} \chi_{V_i}(z).\]
Hence, if \(z\) is such that \(\chi_{V_i}(z) = \dim V_i\) and \(\chi_{V_j}(z) = 0\) 
for all \(j \neq i\), then we obtain that \(z\) is mapped to \(\text{id}_{V_i}\) 
along this isomorphism. 

Let us define 
\[e_{V_i} := \frac{\dim V_i}{|G|} \sum_{g \in G} \overline{\chi_{V_i}(g)}g.\]
Then, we have 
\[\chi_{V_j}(e_{V_i}) = \frac{\dim V_i}{|G|} \sum_{g \in G} 
  \overline{\chi_{V_i}(g)}\chi_{V_j}(g) = \dim V_i \delta_{ij}.\]
Hence, \(\rho_{V_j}(e_{V_i}) = \delta_{ij} \cdot \text{id}_{V_i}\) is a 
\(G\)-linear projection with the image being \(V_i\). In particular, 
we have the isomorphism
\[(\rho_{V_1}(e_{V_1}), \cdots, \rho_{V_n}(e_{V_n})) : 
  V \cong V^1 \oplus \cdots \oplus V^n.\]
We say the this map decomposes \(V\) into isotypic components, i.e. 
\(V^i\) is the span of all subrepresentations of \(V\) isomorphic to 
\(V_i\).

\newpage
\section{Connections to Geometry}

This section will provide some connections between representation theory to 
geometry. All content in this section are not examinable.

\subsection{Dirac Operator and Clifford Algebra}

The Dirac operator is an operator initially motivated by relativistic quantum 
mechanics and is defined to be a square root of the Laplacian operator, i.e. 
the Dirac operator \(D\) is an operator such that 
\[D^2 = \Delta = \pdv[2]{x_1} + \cdots + \pdv[2]{x_n}.\]
The non-relativistic Schrdinger equation (without potential, i.e. free particle) 
is 
\[i\hbar \pdv{\psi}{t} = - \frac{\hbar^2}{2m} \Delta \psi\]
where \(\psi : \mathbb{R}^n \to \mathbb{C}\) is the wave function evolving in 
time. Written in terms of the Hamiltonian \(H\), we have the equation 
\(\dot \psi = H\psi\) (omitting some constants). We note that this equation 
treats time and space separately and is therefore non-relativistic.

In relativity on the other hand, we have the momentum-energy four-vector 
\[p^2 c^2 + m^2 c^4 = E^2\]
where \(p\) is the momentum, \(c\) is the speed of light, \(m\) is the mass 
and \(E\) is the energy. This equation suggests another operator describing 
energy (in contrast to the Hamiltonian) and so, we replace the 
Schrdinger equation with
\[\frac{1}{c^2}\left(i\hbar \pdv{t}\right)^2 \psi + \hbar^2 \Delta\psi = 
  m^2c^2 \psi.\]
Denoting the operator \(\tilde \Delta := 
\left(\frac{i \hbar}{c}\pdv{t}\right)^2 + \left(\hbar \pdv{x_1}\right)^2 + \cdots 
+ \left(\hbar \pdv{x_n}\right)^2\), the equation becomes \(\tilde \Delta \psi = 
m^2 c^2 \psi\). We call \(\tilde \Delta\) the space-time Laplacian. However, 
unlike the Schrdinger equation, this is now a second order differential equation 
and the solution will depend on not only the wave function at time 0, but also 
its derivative at 0. This is problematic as the derivative might be badly behaved 
and \(\psi\) might not be \(L^2\).

Now, if there exists an operator \(D\) such that \(D^2 = \tilde \Delta\), 
we can solve \(D\psi = mc \psi\) and this equation is known as the Dirac equation.
Although it is not yet clear such an operator exists.

For simplicity, assume we are working with the usual Laplacian \(\Delta\) though 
it is not difficult to generalize these ideas.

In the case \(n = 1\), \(D\) is simply the derivative and indeed, 
\(D^2 = \dv[2]{x} = \Delta\). For higher dimensions, we will need to use matrices 
with the solutions being vectors. In particular, for \(n = 2\), we may take 
\[\left(
  \begin{pmatrix}
    0 & 1 \\
    1 & 0
  \end{pmatrix}
  \pdv{x} +
  \begin{pmatrix}
    0 & -i \\
    i & 0
  \end{pmatrix}
  \pdv{y}
\right)^2 = 
  \pdv[2]{x} + \pdv[2]{y} = \Delta,\]
which acts on a vector of functions \((f_1, f_2)^T\). Similarly, 
for \(n = 3\), we have 
\[\left(
  \begin{pmatrix}
    0 & 1 \\
    1 & 0
  \end{pmatrix}
  \pdv{x} +
  \begin{pmatrix}
    0 & -i \\
    i & 0
  \end{pmatrix}
  \pdv{y} + 
  \begin{pmatrix}
    1 & 0 \\
    0 & -1
  \end{pmatrix}
  \pdv{z}
\right)^2 = 
  \pdv[2]{x} + \pdv[2]{y} + \pdv[2]{z} = \Delta.\]
These matrices are known as Pauli matrices and anticommute. In relativity, 
we are intereseted in \(n = 4\) (3 space dimensions and 1 time dimension) 
and in this case, we will need \(4 \times 4\) matrices acting on 
\((f_1, \cdots, f_4)^T\).

From an abstract point of view, we want in general 
\[D = \sum_{i = 1}^n e_i \pdv{x_i} \text{ where } e_i e_j = -e_je_i, e_i^2 = 1\]
for all \(i, j = 1, \cdots, n\), \(i \neq j\).

\begin{definition}[Clifford Algebra]
  The Clifford algebra is 
  \[\mathbb{C}l_n := \frac{\mathbb{C}\langle e_1, \cdots, e_n \rangle}{
    \langle e_i e_j = -e_j e_i, e_1^2 = \cdots = e_n^2 = 1 \rangle}.\]
  We use the angled brackets to stress \(e_i\) do not commute.
\end{definition}

\begin{theorem}[Algebraic version of Bott periodicity]
  \(\mathbb{C}l_{2n} \cong \text{Mat}_{2^n}(\mathbb{C})\) and 
  \(\mathbb{C}l_{2n + 1} \cong \text{Mat}_{2^n}(\mathbb{C}) \oplus 
  \text{Mat}_{2^n}(\mathbb{C})\).
\end{theorem}

\begin{corollary}
  \(\mathbb{C}l_n\) is semisimple and for even \(n\), we have the 
  unique \(2^n\)-dimensional module and for odd \(n\), we have the two 
  unique \(2^n\)-dimensional modules.
\end{corollary}

As a consequence, a Dirac operator \(D\) satisfying \(D^2 = \Delta\) on 
\(\mathbb{R}^n\), we require matrices of size \(2^{\lfloor n / 2\rfloor}\).
Thus, solutions of \(D\psi = \lambda \psi\) are vectors of functions 
\((f_1, \cdots, f_N)^T\) where \(N = 2^{\lfloor n / 2 \rfloor}\).

\begin{definition}[Real Clifford Algebra]
  The real Clifford algebra is 
  \[Cl_{\mathbb{R}}(p, q) := \frac{\mathbb{R}\langle x_1, \cdots, x_{p + q}\rangle}
  {\langle x_i x_j + x_j x_i = 0, x_1^2 = \cdots = x_p^2 = 1, 
    x_{p + 1}^2 = \cdots = x_{p + q}^2 = -1\rangle}.\]
\end{definition}

We note \(Cl_{\mathbb{R}}(0, q)\) is \(\mathbb{R}\) for \(q = 0\), \(\mathbb{C}\) 
for \(q = 1\) and \(\mathbb{H}\) for \(q = 2\).

With this in mind, the Pauli matrices are simply the values of the Clifford 
algebra written as matrices.

\subsubsection{The Spin Group}

Let us recall the orthogonal and special orthogonal group. In particular, we 
have the groups 
\[O(n, \mathbb{R}) := \{A \in GL_n(\mathbb{R}) \mid A^T = A^{-1}\},\]
and 
\[SO(n, \mathbb{R}) := \{A \in O(n, \mathbb{R}) \mid \det A = 1\}.\]
In particular, as \(A^T = A^{-1}\) implies \(\det A = \pm 1\), we may think 
the orthogonal group as the group of isometries while the special orthogonal 
group as the subgroup of the orthogonal group which preserves the orientation.

We observe that \(O(n, \mathbb{R})\) preserves the dot product and the norm, 
and so, it preserves the Laplacian. With this, the orthogonal group acts 
on the Clifford algebra where 
\(e_i \mapsto Ae_i\)
for all \(A \in O(n, \mathbb{R})\). Furthermore, these actions can be obtained 
by conjugation. With this, conjugation provides a surjective homomorphism from 
\(S^3\) to \(SO(3, \mathbb{R}) \hookrightarrow \mathbb{R}i \oplus \mathbb{R}j 
\oplus \mathbb{R}k\) where the map has kernel \(\{\pm 1\}\) (the center).
With this, \(SO(3, \mathbb{R})\) has a nontrivial covering \(S^3\) and this 
is called the ``spin group''.

We may construct the spin group in general using the Clifford algebra.
Insider \(Cl_{\mathbb{R}}(0, n)\), we have the unit vectors \(v \in \mathbb{R}^n 
\subseteq Cl_{\mathbb{R}}(0, n)\), i.e. \(v \cdot v = 1 \iff v^2 = -1\) in 
\(\mathbb{Cl}_{\mathbb{R}}(0, n)\). Now, the mapping \(w \mapsto v w v\) is a
reflection as \(v^2 = -1\). Generally, defining 
\[\text{Pin}(n, \mathbb{R}) := \langle v \in \mathbb{R}^n \mid v^2 = -1 \rangle 
\to O(n, \mathbb{R}) : v \mapsto (w \mapsto v w v),\]
we have a subgroup \(\text{Spin}(n, \mathbb{R}) \le \text{Pin}(n, \mathbb{R})\) 
such that 
\[\text{Spin}(n, \mathbb{R}) := \langle v, w \in \mathbb{R}^n \mid v^2 = -1 = w^2 
\rangle \to SO(n, \mathbb{R})\]
which maps product of even number of unit vectors to the product of even number 
of reflections. One may similarly define \(\text{Spin}(n, \mathbb{C}) \subseteq 
\mathbb{C}l(n)\) and \(\text{Spin}(p, q, \mathbb{R}) \subseteq Cl_{\mathbb{R}}(p, q)\).

Generally, spin and pin do act as subgroups of the Clifford algebra. As a consequence 
of this, using the compatibility of the spinor \(2^{\lfloor n / 2 \rfloor}\)-dimensional 
module over the Clifford algebra with orthogonal transformations, we can define the 
Dirac operator not just on \(\mathbb{R}^n\) be on ``spin'' manifolds.

\begin{proposition}
  The irreducible representations of \(SO(n, \mathbb{R})\) are natural 
  subspaces of \((\mathbb{R}^n)^{\otimes m}\) for \(m \ge 0\) up to 
  isomorphism.
\end{proposition}

\begin{proposition}
  The irreducible complex representations of \(\text{Spin}(n, \mathbb{R})\) are 
  the above and the natural subspaces of the \(2^{\lfloor n / 2 \rfloor}\)-dimensional 
  representations of \(\mathbb{C}l(n)\) and their tensor powers up to isomorphism.
\end{proposition}


\end{document} 
